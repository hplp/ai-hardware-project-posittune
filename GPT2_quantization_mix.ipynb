{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVEKHkvBS8iy",
        "outputId": "458a58da-c017-47d9-c313-2b4dd83d1fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating table for 2^(I.F), I=2, F=1 \n",
            "power 2 table:  [-4.0, -3.5, -3.0, -2.5, -2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
            "system 2^(2.1):  [0.0625, 0.08838834764831845, 0.125, 0.1767766952966369, 0.25, 0.3535533905932738, 0.5, 0.7071067811865476, 1.0, 1.4142135623730951, 2.0, 2.8284271247461903, 4.0, 5.656854249492381, 8.0, 11.313708498984761]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_log2system(int_length, fraction_length):\n",
        "  #system 2^(I.F)\n",
        "  print (\"generating table for 2^(I.F), I=%d, F=%d \"%(int_length,fraction_length))\n",
        "  step  =  2**(-fraction_length)\n",
        "  power_table = np.arange(-2**int_length,  2**int_length, step)\n",
        "  print (\"power 2 table: \", list(power_table))\n",
        "  table = list(map(lambda x: 2.0**x, power_table))\n",
        "  print (\"system 2^(%d.%d): \"%(int_length,fraction_length), table)\n",
        "  return table\n",
        "\n",
        "weight_table = generate_log2system(2,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R89-lb3TB1O",
        "outputId": "9b8414b0-39fd-4a20-8a09-6f9ab5ced0dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed May 21 17:36:01 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 575.51.02              Driver Version: 576.02         CUDA Version: 12.9     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3060        On  |   00000000:03:00.0  On |                  N/A |\n",
            "| 58%   53C    P3             28W /  170W |    2478MiB /  12288MiB |     17%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Requirement already satisfied: transformers in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (4.46.3)\n",
            "Requirement already satisfied: datasets in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/yimin/.local/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/yimin/.local/lib/python3.12/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /home/yimin/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/yimin/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: xxhash in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in /home/yimin/.local/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yimin/.local/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/yimin/.local/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/yimin/.local/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: nlp in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /home/yimin/.local/lib/python3.12/site-packages (from nlp) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from nlp) (18.1.0)\n",
            "Requirement already satisfied: dill in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from nlp) (0.3.8)\n",
            "Requirement already satisfied: pandas in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from nlp) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/yimin/.local/lib/python3.12/site-packages (from nlp) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from nlp) (4.66.5)\n",
            "Requirement already satisfied: filelock in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from nlp) (3.16.1)\n",
            "Requirement already satisfied: xxhash in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from nlp) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yimin/.local/lib/python3.12/site-packages (from requests>=2.19.0->nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/yimin/.local/lib/python3.12/site-packages (from requests>=2.19.0->nlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from requests>=2.19.0->nlp) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/yimin/.local/lib/python3.12/site-packages (from requests>=2.19.0->nlp) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/yimin/.local/lib/python3.12/site-packages (from pandas->nlp) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from pandas->nlp) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from pandas->nlp) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->nlp) (1.17.0)\n",
            "fatal: destination path 'QPyTorch' already exists and is not an empty directory.\n",
            "error: pathspec 'posit-constant-generation' did not match any file(s) known to git\n",
            "\u001b[31mERROR: Directory './' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: ninja in /home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages (1.11.1.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!nvidia-smi\n",
        "!pip install transformers datasets\n",
        "!pip install nlp\n",
        "\n",
        "!git clone https://github.com/minhhn2910/QPyTorch\n",
        "try:\n",
        "  os.chdir('/content/QPyTorch')\n",
        "except:\n",
        "  pass\n",
        "!git checkout posit-constant-generation\n",
        "\n",
        "!pip install ./\n",
        "!pip install ninja\n",
        "\n",
        "try:\n",
        "  os.chdir('/content/')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  raise RuntimeError('Cannot run this cell without GPU runtime.')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "00ad030852364c5d9a91c791967b579a",
            "c538629f4cc442bcb3b43d0a0bf58865",
            "b7f9d65a2a424b96942d421156932b39",
            "ebc1e222709342ab81e7e49f3d6e58f0",
            "b5b8259396944af190739387c4f3e987",
            "d245544116bc41939980a2dd1291859f",
            "0fc0d243561544709472a6d171374909",
            "cde7244069be49fab5489502a5c00389",
            "c28630d899bb4e6992860b3e93bf515e",
            "062f41eb2a1046808f65ea6e440f0df3",
            "82f17d89785944af95b20cc3af2f138a",
            "af9d5f752d0c4116b8f8a5ef96991961",
            "c8d828ebbbfb4f2b840cac7cebc1e8c6",
            "83cf1f99cdfb47e98dfd30f7b6660936",
            "e9d602a86e8f49b189ef4c306ae2f628",
            "373a4c4089414f5cb857d63e269dd336",
            "c009bb702dbb42a8a390492e611de786",
            "33ad620366684e3aafd65ca4fe9d3837",
            "4574302ffe6344cda2db49aa4799c90f",
            "225c77726c2443cf9907c6f342dc6989",
            "e87e99711e224653900bdf4f5a46e340",
            "96631b351a46456abe8267156ace46e5",
            "78404c0b802e4e9c89a49859ab6406e3",
            "f6dae690b8964dc4b7270bcd31d6af37",
            "8441693459d0482dbafb27ba6e532fcc",
            "8279318bbd8e40699e4b9b3db3e1feea",
            "79a60ae742c24c379d54e59dc0ef7d8c",
            "c006b510a3cb43c5a2d8e33776ffbf5f",
            "ce0d05fbf1df49d6bf6fd7a729b3a014",
            "c2ae0017ab8c4ef899693f54a572cbb8",
            "150b806ba66b47dfb8fb3f2e941502ea",
            "23ce38918cc34c3fb6afff61502766a2",
            "f41d1255fa1740478ccdd55465546315",
            "a41b135f629f441292511e486547525a",
            "e474c5a4f3024f709a08e8287218ba8f",
            "44e97f109e534534b04598f341bd086b",
            "3eb48787e3b04faea1b39441977cb032",
            "43e9937624404bebbd8101130f140bdc",
            "2debd06b648343dd9c3d2e2793c9f5bf",
            "560f75060fc845959bbe92a3e9e10cdc",
            "01ea0430af0b47ebbb292b97c7fa00ce",
            "ebb54ddafa244e4da5263217e36e089c",
            "69204362e6ef4678971d614fb0686aca",
            "27e0c123bafd44579e1ec77a17888b24",
            "fce111d5fb084d369dbef665f0bda3fe",
            "00739f8e753d4f7cb7a11ad8ef98184d",
            "691ee1705e06443e96711cbef3140736",
            "d69b05587cf64f60a8e7f8b42c3ee47b",
            "8fbcb321cd3247ccb77b9fa3807982dd",
            "cbaf4bd3655f49e5afa3e85c23429054",
            "8579e8bcea83406287627c31c49ee4b3",
            "90f92d26cc6f44da8bfa93ba123b13e1",
            "382f254a57ce4da5a0ecd9b291395669",
            "26ea1aaefd7244388b0af89fcf3defa7",
            "c0ee4f7c6ad944fea9b42c3ab8fb175a",
            "0e2e53cdddc142fd915c9309e98f570b",
            "c02b7a8f028544f9ba49d1836a31ce2f",
            "840cf52790c14b98ad50643f0be8e297",
            "5f3bda09bbf3411292b41f380522bd2a",
            "c4ce3eb5761f4fd9a9b6293800994570",
            "b3534fdd71364144a9f4d270c18b028d",
            "8dff12e8a5844b538c907310f6d1a595",
            "c53a1b3b4b18495c99a11e5f39d396eb",
            "ed9f7a93361c45d1bc18890c4b355766",
            "912ffd0281cb44dfb011ce1d9117dff9",
            "b13827923c7a4a01b81254c069ea3c2d",
            "51adb325cf614081ac5e83b62313bc56",
            "eac5cd46cda34846869a1ab8ba750139",
            "ffde35caf0c441c5bc2cf3253753b970",
            "3aa7601c692144b6afe29aac12ea4a93",
            "987ffebd2fbb4491925236934a425ecb",
            "e52fae3f086b45a1b4ee9f8de1da72ae",
            "7522cb91f9294e048895b0271a8950b0",
            "3fddcc80d6224dbb9c8d12818652f293",
            "8110dd23c8024748a1200a6f002a4feb",
            "6a777e8f71424286bafbaee44d6298dd",
            "887f8c6577624e468aeedd5e0719ed47"
          ]
        },
        "id": "hyS_3JS5vkUz",
        "outputId": "664ad443-ae64-4186-c5ca-c45a4519aab1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yimin/miniconda3/envs/posit/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-05-21 17:36:06.163432: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-21 17:36:06.170258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-05-21 17:36:06.178543: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-05-21 17:36:06.181104: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:36:06.187528: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-21 17:36:06.641329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listing all layers in the model:\n",
            " : <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
            "transformer : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n",
            "transformer.wte : <class 'torch.nn.modules.sparse.Embedding'>\n",
            "transformer.wpe : <class 'torch.nn.modules.sparse.Embedding'>\n",
            "transformer.drop : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h : <class 'torch.nn.modules.container.ModuleList'>\n",
            "transformer.h.0 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.0.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.0.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.0.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.0.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.0.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.0.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.0.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.0.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.1 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.1.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.1.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.1.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.1.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.1.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.1.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.1.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.1.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.2 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.2.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.2.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.2.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.2.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.2.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.2.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.2.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.2.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.3 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.3.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.3.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.3.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.3.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.3.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.3.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.3.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.3.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.4 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.4.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.4.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.4.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.4.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.4.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.4.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.4.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.4.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.5 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.5.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.5.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.5.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.5.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.5.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.5.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.5.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.5.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.6 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.6.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.6.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.6.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.6.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.6.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.6.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.6.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.6.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.7 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.7.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.7.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.7.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.7.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.7.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.7.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.7.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.7.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.8 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.8.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.8.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.8.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.8.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.8.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.8.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.8.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.8.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.9 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.9.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.9.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.9.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.9.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.9.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.9.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.9.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.9.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.10 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.10.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.10.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.10.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.10.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.10.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.10.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.10.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.10.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.11 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.11.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.11.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.11.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.11.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.11.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.11.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.11.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.11.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.12 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.12.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.12.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.12.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.12.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.12.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.12.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.12.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.12.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.12.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.12.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.12.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.12.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.13 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.13.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.13.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.13.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.13.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.13.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.13.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.13.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.13.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.13.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.13.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.13.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.13.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.14 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.14.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.14.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.14.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.14.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.14.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.14.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.14.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.14.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.14.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.14.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.14.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.14.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.15 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.15.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.15.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.15.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.15.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.15.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.15.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.15.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.15.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.15.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.15.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.15.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.15.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.16 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.16.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.16.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.16.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.16.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.16.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.16.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.16.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.16.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.16.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.16.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.16.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.16.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.17 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.17.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.17.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.17.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.17.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.17.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.17.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.17.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.17.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.17.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.17.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.17.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.17.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.18 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.18.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.18.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.18.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.18.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.18.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.18.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.18.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.18.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.18.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.18.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.18.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.18.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.19 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.19.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.19.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.19.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.19.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.19.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.19.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.19.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.19.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.19.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.19.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.19.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.19.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.20 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.20.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.20.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.20.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.20.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.20.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.20.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.20.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.20.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.20.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.20.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.20.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.20.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.21 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.21.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.21.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.21.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.21.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.21.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.21.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.21.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.21.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.21.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.21.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.21.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.21.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.22 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.22.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.22.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.22.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.22.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.22.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.22.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.22.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.22.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.22.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.22.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.22.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.22.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.23 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.23.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.23.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.23.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.23.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.23.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.23.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.23.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.23.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.23.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.23.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.23.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.23.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.24 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.24.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.24.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.24.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.24.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.24.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.24.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.24.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.24.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.24.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.24.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.24.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.24.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.25 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.25.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.25.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.25.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.25.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.25.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.25.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.25.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.25.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.25.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.25.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.25.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.25.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.26 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.26.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.26.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.26.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.26.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.26.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.26.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.26.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.26.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.26.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.26.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.26.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.26.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.27 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.27.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.27.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.27.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.27.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.27.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.27.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.27.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.27.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.27.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.27.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.27.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.27.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.28 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.28.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.28.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.28.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.28.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.28.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.28.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.28.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.28.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.28.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.28.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.28.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.28.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.29 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.29.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.29.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.29.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.29.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.29.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.29.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.29.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.29.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.29.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.29.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.29.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.29.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.30 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.30.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.30.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.30.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.30.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.30.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.30.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.30.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.30.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.30.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.30.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.30.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.30.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.31 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.31.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.31.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.31.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.31.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.31.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.31.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.31.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.31.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.31.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.31.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.31.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.31.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.32 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.32.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.32.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.32.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.32.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.32.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.32.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.32.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.32.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.32.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.32.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.32.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.32.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.33 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.33.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.33.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.33.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.33.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.33.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.33.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.33.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.33.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.33.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.33.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.33.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.33.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.34 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.34.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.34.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.34.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.34.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.34.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.34.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.34.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.34.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.34.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.34.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.34.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.34.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.35 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.35.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.35.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.35.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.35.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.35.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.35.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.35.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.35.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.35.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.35.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.35.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.35.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.ln_f : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "lm_head : <class 'torch.nn.modules.linear.Linear'>\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "device = 'cuda'\n",
        "model_id = 'gpt2-large'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_id)\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
        "# Print all layer names\n",
        "print(\"Listing all layers in the model:\")\n",
        "for name, module in model.named_modules():\n",
        "    print(name, \":\", type(module))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfU75mekvoTj",
        "outputId": "039cccd4-299c-4753-cad1-79b922b89c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "[0.0065918  0.02197266 0.0402832  0.0625     0.08514404 0.12109375\n",
            " 0.2109375  0.53640747]\n",
            "[0.015625   0.0625     0.125      0.1640625  0.29296875 0.4375\n",
            " 0.625      0.84375    1.         1.25       1.5        2.11486816\n",
            " 3.08789062 4.25       6.         8.25      ]\n",
            "Processing embedding layer: transformer.wte\n",
            "x_with_max_frequency for transformer.wte: -4.24\n",
            "Quantized embedding layer transformer.wte with scale factor: 1.89e+01\n",
            "Processing embedding layer: transformer.wpe\n",
            "x_with_max_frequency for transformer.wpe: -11.83\n",
            "Quantized embedding layer transformer.wpe with scale factor: 3.63e+03\n",
            "Processing layer: transformer.h.0.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.0.attn.c_attn: -8.44\n",
            "Quantized layer transformer.h.0.attn.c_attn with scale factor: 3.46e+02\n",
            "Processing layer: transformer.h.0.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.0.attn.c_proj: -9.20\n",
            "Quantized layer transformer.h.0.attn.c_proj with scale factor: 5.88e+02\n",
            "Processing layer: transformer.h.0.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.0.mlp.c_fc: -8.47\n",
            "Quantized layer transformer.h.0.mlp.c_fc with scale factor: 3.54e+02\n",
            "Processing layer: transformer.h.0.mlp.c_proj\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2800/2746343755.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  quantized_weights = posit_quantize(torch.tensor(module.weight.data, dtype=torch.float32), nsize=6, es=0, scale=scale)\n",
            "/tmp/ipykernel_2800/2746343755.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  quantized_weights = posit_quantize(torch.tensor(module.weight.data, dtype=torch.float32), nsize=6, es=0, scale=scale)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_with_max_frequency for transformer.h.0.mlp.c_proj: -9.02\n",
            "Quantized layer transformer.h.0.mlp.c_proj with scale factor: 5.20e+02\n",
            "Processing layer: transformer.h.1.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.1.attn.c_attn: -8.56\n",
            "Quantized layer transformer.h.1.attn.c_attn with scale factor: 3.78e+02\n",
            "Processing layer: transformer.h.1.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.1.attn.c_proj: -8.97\n",
            "Quantized layer transformer.h.1.attn.c_proj with scale factor: 5.00e+02\n",
            "Processing layer: transformer.h.1.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.1.mlp.c_fc: -8.40\n",
            "Quantized layer transformer.h.1.mlp.c_fc with scale factor: 3.38e+02\n",
            "Processing layer: transformer.h.1.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.1.mlp.c_proj: -8.65\n",
            "Quantized layer transformer.h.1.mlp.c_proj with scale factor: 4.02e+02\n",
            "Processing layer: transformer.h.2.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.2.attn.c_attn: -8.78\n",
            "Quantized layer transformer.h.2.attn.c_attn with scale factor: 4.41e+02\n",
            "Processing layer: transformer.h.2.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.2.attn.c_proj: -9.00\n",
            "Quantized layer transformer.h.2.attn.c_proj with scale factor: 5.12e+02\n",
            "Processing layer: transformer.h.2.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.2.mlp.c_fc: -8.29\n",
            "Quantized layer transformer.h.2.mlp.c_fc with scale factor: 3.13e+02\n",
            "Processing layer: transformer.h.2.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.2.mlp.c_proj: -8.58\n",
            "Quantized layer transformer.h.2.mlp.c_proj with scale factor: 3.83e+02\n",
            "Processing layer: transformer.h.3.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.3.attn.c_attn: -8.93\n",
            "Quantized layer transformer.h.3.attn.c_attn with scale factor: 4.86e+02\n",
            "Processing layer: transformer.h.3.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.3.attn.c_proj: -8.81\n",
            "Quantized layer transformer.h.3.attn.c_proj with scale factor: 4.48e+02\n",
            "Processing layer: transformer.h.3.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.3.mlp.c_fc: -8.38\n",
            "Quantized layer transformer.h.3.mlp.c_fc with scale factor: 3.34e+02\n",
            "Processing layer: transformer.h.3.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.3.mlp.c_proj: -8.53\n",
            "Quantized layer transformer.h.3.mlp.c_proj with scale factor: 3.69e+02\n",
            "Processing layer: transformer.h.4.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.4.attn.c_attn: -8.73\n",
            "Quantized layer transformer.h.4.attn.c_attn with scale factor: 4.24e+02\n",
            "Processing layer: transformer.h.4.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.4.attn.c_proj: -8.85\n",
            "Quantized layer transformer.h.4.attn.c_proj with scale factor: 4.60e+02\n",
            "Processing layer: transformer.h.4.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.4.mlp.c_fc: -8.42\n",
            "Quantized layer transformer.h.4.mlp.c_fc with scale factor: 3.43e+02\n",
            "Processing layer: transformer.h.4.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.4.mlp.c_proj: -8.53\n",
            "Quantized layer transformer.h.4.mlp.c_proj with scale factor: 3.70e+02\n",
            "Processing layer: transformer.h.5.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.5.attn.c_attn: -8.67\n",
            "Quantized layer transformer.h.5.attn.c_attn with scale factor: 4.09e+02\n",
            "Processing layer: transformer.h.5.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.5.attn.c_proj: -8.87\n",
            "Quantized layer transformer.h.5.attn.c_proj with scale factor: 4.69e+02\n",
            "Processing layer: transformer.h.5.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.5.mlp.c_fc: -8.46\n",
            "Quantized layer transformer.h.5.mlp.c_fc with scale factor: 3.52e+02\n",
            "Processing layer: transformer.h.5.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.5.mlp.c_proj: -8.47\n",
            "Quantized layer transformer.h.5.mlp.c_proj with scale factor: 3.54e+02\n",
            "Processing layer: transformer.h.6.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.6.attn.c_attn: -8.64\n",
            "Quantized layer transformer.h.6.attn.c_attn with scale factor: 3.99e+02\n",
            "Processing layer: transformer.h.6.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.6.attn.c_proj: -8.80\n",
            "Quantized layer transformer.h.6.attn.c_proj with scale factor: 4.45e+02\n",
            "Processing layer: transformer.h.6.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.6.mlp.c_fc: -8.33\n",
            "Quantized layer transformer.h.6.mlp.c_fc with scale factor: 3.21e+02\n",
            "Processing layer: transformer.h.6.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.6.mlp.c_proj: -8.49\n",
            "Quantized layer transformer.h.6.mlp.c_proj with scale factor: 3.61e+02\n",
            "Processing layer: transformer.h.7.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.7.attn.c_attn: -8.52\n",
            "Quantized layer transformer.h.7.attn.c_attn with scale factor: 3.68e+02\n",
            "Processing layer: transformer.h.7.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.7.attn.c_proj: -8.80\n",
            "Quantized layer transformer.h.7.attn.c_proj with scale factor: 4.47e+02\n",
            "Processing layer: transformer.h.7.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.7.mlp.c_fc: -8.44\n",
            "Quantized layer transformer.h.7.mlp.c_fc with scale factor: 3.48e+02\n",
            "Processing layer: transformer.h.7.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.7.mlp.c_proj: -8.56\n",
            "Quantized layer transformer.h.7.mlp.c_proj with scale factor: 3.78e+02\n",
            "Processing layer: transformer.h.8.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.8.attn.c_attn: -8.67\n",
            "Quantized layer transformer.h.8.attn.c_attn with scale factor: 4.06e+02\n",
            "Processing layer: transformer.h.8.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.8.attn.c_proj: -8.70\n",
            "Quantized layer transformer.h.8.attn.c_proj with scale factor: 4.15e+02\n",
            "Processing layer: transformer.h.8.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.8.mlp.c_fc: -8.33\n",
            "Quantized layer transformer.h.8.mlp.c_fc with scale factor: 3.21e+02\n",
            "Processing layer: transformer.h.8.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.8.mlp.c_proj: -8.58\n",
            "Quantized layer transformer.h.8.mlp.c_proj with scale factor: 3.83e+02\n",
            "Processing layer: transformer.h.9.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.9.attn.c_attn: -8.49\n",
            "Quantized layer transformer.h.9.attn.c_attn with scale factor: 3.59e+02\n",
            "Processing layer: transformer.h.9.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.9.attn.c_proj: -8.66\n",
            "Quantized layer transformer.h.9.attn.c_proj with scale factor: 4.06e+02\n",
            "Processing layer: transformer.h.9.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.9.mlp.c_fc: -8.39\n",
            "Quantized layer transformer.h.9.mlp.c_fc with scale factor: 3.36e+02\n",
            "Processing layer: transformer.h.9.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.9.mlp.c_proj: -8.70\n",
            "Quantized layer transformer.h.9.mlp.c_proj with scale factor: 4.15e+02\n",
            "Processing layer: transformer.h.10.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.10.attn.c_attn: -8.38\n",
            "Quantized layer transformer.h.10.attn.c_attn with scale factor: 3.33e+02\n",
            "Processing layer: transformer.h.10.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.10.attn.c_proj: -8.80\n",
            "Quantized layer transformer.h.10.attn.c_proj with scale factor: 4.47e+02\n",
            "Processing layer: transformer.h.10.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.10.mlp.c_fc: -8.41\n",
            "Quantized layer transformer.h.10.mlp.c_fc with scale factor: 3.41e+02\n",
            "Processing layer: transformer.h.10.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.10.mlp.c_proj: -8.60\n",
            "Quantized layer transformer.h.10.mlp.c_proj with scale factor: 3.88e+02\n",
            "Processing layer: transformer.h.11.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.11.attn.c_attn: -8.36\n",
            "Quantized layer transformer.h.11.attn.c_attn with scale factor: 3.29e+02\n",
            "Processing layer: transformer.h.11.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.11.attn.c_proj: -8.60\n",
            "Quantized layer transformer.h.11.attn.c_proj with scale factor: 3.89e+02\n",
            "Processing layer: transformer.h.11.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.11.mlp.c_fc: -8.33\n",
            "Quantized layer transformer.h.11.mlp.c_fc with scale factor: 3.22e+02\n",
            "Processing layer: transformer.h.11.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.11.mlp.c_proj: -8.49\n",
            "Quantized layer transformer.h.11.mlp.c_proj with scale factor: 3.59e+02\n",
            "Processing layer: transformer.h.12.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.12.attn.c_attn: -8.47\n",
            "Quantized layer transformer.h.12.attn.c_attn with scale factor: 3.55e+02\n",
            "Processing layer: transformer.h.12.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.12.attn.c_proj: -8.71\n",
            "Quantized layer transformer.h.12.attn.c_proj with scale factor: 4.20e+02\n",
            "Processing layer: transformer.h.12.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.12.mlp.c_fc: -8.45\n",
            "Quantized layer transformer.h.12.mlp.c_fc with scale factor: 3.50e+02\n",
            "Processing layer: transformer.h.12.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.12.mlp.c_proj: -8.49\n",
            "Quantized layer transformer.h.12.mlp.c_proj with scale factor: 3.60e+02\n",
            "Processing layer: transformer.h.13.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.13.attn.c_attn: -8.46\n",
            "Quantized layer transformer.h.13.attn.c_attn with scale factor: 3.52e+02\n",
            "Processing layer: transformer.h.13.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.13.attn.c_proj: -8.71\n",
            "Quantized layer transformer.h.13.attn.c_proj with scale factor: 4.18e+02\n",
            "Processing layer: transformer.h.13.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.13.mlp.c_fc: -8.32\n",
            "Quantized layer transformer.h.13.mlp.c_fc with scale factor: 3.20e+02\n",
            "Processing layer: transformer.h.13.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.13.mlp.c_proj: -8.53\n",
            "Quantized layer transformer.h.13.mlp.c_proj with scale factor: 3.70e+02\n",
            "Processing layer: transformer.h.14.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.14.attn.c_attn: -8.48\n",
            "Quantized layer transformer.h.14.attn.c_attn with scale factor: 3.56e+02\n",
            "Processing layer: transformer.h.14.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.14.attn.c_proj: -8.67\n",
            "Quantized layer transformer.h.14.attn.c_proj with scale factor: 4.06e+02\n",
            "Processing layer: transformer.h.14.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.14.mlp.c_fc: -8.29\n",
            "Quantized layer transformer.h.14.mlp.c_fc with scale factor: 3.13e+02\n",
            "Processing layer: transformer.h.14.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.14.mlp.c_proj: -8.72\n",
            "Quantized layer transformer.h.14.mlp.c_proj with scale factor: 4.20e+02\n",
            "Processing layer: transformer.h.15.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.15.attn.c_attn: -8.32\n",
            "Quantized layer transformer.h.15.attn.c_attn with scale factor: 3.21e+02\n",
            "Processing layer: transformer.h.15.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.15.attn.c_proj: -8.63\n",
            "Quantized layer transformer.h.15.attn.c_proj with scale factor: 3.95e+02\n",
            "Processing layer: transformer.h.15.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.15.mlp.c_fc: -8.28\n",
            "Quantized layer transformer.h.15.mlp.c_fc with scale factor: 3.10e+02\n",
            "Processing layer: transformer.h.15.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.15.mlp.c_proj: -8.71\n",
            "Quantized layer transformer.h.15.mlp.c_proj with scale factor: 4.19e+02\n",
            "Processing layer: transformer.h.16.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.16.attn.c_attn: -8.49\n",
            "Quantized layer transformer.h.16.attn.c_attn with scale factor: 3.60e+02\n",
            "Processing layer: transformer.h.16.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.16.attn.c_proj: -8.49\n",
            "Quantized layer transformer.h.16.attn.c_proj with scale factor: 3.60e+02\n",
            "Processing layer: transformer.h.16.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.16.mlp.c_fc: -8.30\n",
            "Quantized layer transformer.h.16.mlp.c_fc with scale factor: 3.16e+02\n",
            "Processing layer: transformer.h.16.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.16.mlp.c_proj: -8.51\n",
            "Quantized layer transformer.h.16.mlp.c_proj with scale factor: 3.65e+02\n",
            "Processing layer: transformer.h.17.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.17.attn.c_attn: -8.37\n",
            "Quantized layer transformer.h.17.attn.c_attn with scale factor: 3.30e+02\n",
            "Processing layer: transformer.h.17.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.17.attn.c_proj: -8.47\n",
            "Quantized layer transformer.h.17.attn.c_proj with scale factor: 3.56e+02\n",
            "Processing layer: transformer.h.17.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.17.mlp.c_fc: -8.52\n",
            "Quantized layer transformer.h.17.mlp.c_fc with scale factor: 3.66e+02\n",
            "Processing layer: transformer.h.17.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.17.mlp.c_proj: -8.47\n",
            "Quantized layer transformer.h.17.mlp.c_proj with scale factor: 3.54e+02\n",
            "Processing layer: transformer.h.18.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.18.attn.c_attn: -8.26\n",
            "Quantized layer transformer.h.18.attn.c_attn with scale factor: 3.07e+02\n",
            "Processing layer: transformer.h.18.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.18.attn.c_proj: -8.24\n",
            "Quantized layer transformer.h.18.attn.c_proj with scale factor: 3.02e+02\n",
            "Processing layer: transformer.h.18.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.18.mlp.c_fc: -8.49\n",
            "Quantized layer transformer.h.18.mlp.c_fc with scale factor: 3.58e+02\n",
            "Processing layer: transformer.h.18.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.18.mlp.c_proj: -8.44\n",
            "Quantized layer transformer.h.18.mlp.c_proj with scale factor: 3.48e+02\n",
            "Processing layer: transformer.h.19.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.19.attn.c_attn: -8.36\n",
            "Quantized layer transformer.h.19.attn.c_attn with scale factor: 3.28e+02\n",
            "Processing layer: transformer.h.19.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.19.attn.c_proj: -8.31\n",
            "Quantized layer transformer.h.19.attn.c_proj with scale factor: 3.17e+02\n",
            "Processing layer: transformer.h.19.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.19.mlp.c_fc: -8.55\n",
            "Quantized layer transformer.h.19.mlp.c_fc with scale factor: 3.74e+02\n",
            "Processing layer: transformer.h.19.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.19.mlp.c_proj: -8.49\n",
            "Quantized layer transformer.h.19.mlp.c_proj with scale factor: 3.59e+02\n",
            "Processing layer: transformer.h.20.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.20.attn.c_attn: -8.44\n",
            "Quantized layer transformer.h.20.attn.c_attn with scale factor: 3.47e+02\n",
            "Processing layer: transformer.h.20.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.20.attn.c_proj: -8.36\n",
            "Quantized layer transformer.h.20.attn.c_proj with scale factor: 3.28e+02\n",
            "Processing layer: transformer.h.20.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.20.mlp.c_fc: -8.31\n",
            "Quantized layer transformer.h.20.mlp.c_fc with scale factor: 3.17e+02\n",
            "Processing layer: transformer.h.20.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.20.mlp.c_proj: -8.45\n",
            "Quantized layer transformer.h.20.mlp.c_proj with scale factor: 3.49e+02\n",
            "Processing layer: transformer.h.21.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.21.attn.c_attn: -8.29\n",
            "Quantized layer transformer.h.21.attn.c_attn with scale factor: 3.13e+02\n",
            "Processing layer: transformer.h.21.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.21.attn.c_proj: -8.45\n",
            "Quantized layer transformer.h.21.attn.c_proj with scale factor: 3.50e+02\n",
            "Processing layer: transformer.h.21.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.21.mlp.c_fc: -8.51\n",
            "Quantized layer transformer.h.21.mlp.c_fc with scale factor: 3.64e+02\n",
            "Processing layer: transformer.h.21.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.21.mlp.c_proj: -8.43\n",
            "Quantized layer transformer.h.21.mlp.c_proj with scale factor: 3.44e+02\n",
            "Processing layer: transformer.h.22.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.22.attn.c_attn: -8.31\n",
            "Quantized layer transformer.h.22.attn.c_attn with scale factor: 3.17e+02\n",
            "Processing layer: transformer.h.22.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.22.attn.c_proj: -8.31\n",
            "Quantized layer transformer.h.22.attn.c_proj with scale factor: 3.17e+02\n",
            "Processing layer: transformer.h.22.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.22.mlp.c_fc: -8.52\n",
            "Quantized layer transformer.h.22.mlp.c_fc with scale factor: 3.66e+02\n",
            "Processing layer: transformer.h.22.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.22.mlp.c_proj: -8.39\n",
            "Quantized layer transformer.h.22.mlp.c_proj with scale factor: 3.37e+02\n",
            "Processing layer: transformer.h.23.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.23.attn.c_attn: -8.42\n",
            "Quantized layer transformer.h.23.attn.c_attn with scale factor: 3.43e+02\n",
            "Processing layer: transformer.h.23.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.23.attn.c_proj: -8.44\n",
            "Quantized layer transformer.h.23.attn.c_proj with scale factor: 3.48e+02\n",
            "Processing layer: transformer.h.23.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.23.mlp.c_fc: -8.47\n",
            "Quantized layer transformer.h.23.mlp.c_fc with scale factor: 3.54e+02\n",
            "Processing layer: transformer.h.23.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.23.mlp.c_proj: -8.42\n",
            "Quantized layer transformer.h.23.mlp.c_proj with scale factor: 3.43e+02\n",
            "Processing layer: transformer.h.24.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.24.attn.c_attn: -8.36\n",
            "Quantized layer transformer.h.24.attn.c_attn with scale factor: 3.29e+02\n",
            "Processing layer: transformer.h.24.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.24.attn.c_proj: -8.39\n",
            "Quantized layer transformer.h.24.attn.c_proj with scale factor: 3.36e+02\n",
            "Processing layer: transformer.h.24.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.24.mlp.c_fc: -8.34\n",
            "Quantized layer transformer.h.24.mlp.c_fc with scale factor: 3.25e+02\n",
            "Processing layer: transformer.h.24.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.24.mlp.c_proj: -8.16\n",
            "Quantized layer transformer.h.24.mlp.c_proj with scale factor: 2.86e+02\n",
            "Processing layer: transformer.h.25.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.25.attn.c_attn: -8.33\n",
            "Quantized layer transformer.h.25.attn.c_attn with scale factor: 3.21e+02\n",
            "Processing layer: transformer.h.25.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.25.attn.c_proj: -8.27\n",
            "Quantized layer transformer.h.25.attn.c_proj with scale factor: 3.08e+02\n",
            "Processing layer: transformer.h.25.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.25.mlp.c_fc: -8.49\n",
            "Quantized layer transformer.h.25.mlp.c_fc with scale factor: 3.60e+02\n",
            "Processing layer: transformer.h.25.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.25.mlp.c_proj: -8.21\n",
            "Quantized layer transformer.h.25.mlp.c_proj with scale factor: 2.97e+02\n",
            "Processing layer: transformer.h.26.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.26.attn.c_attn: -8.46\n",
            "Quantized layer transformer.h.26.attn.c_attn with scale factor: 3.52e+02\n",
            "Processing layer: transformer.h.26.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.26.attn.c_proj: -8.25\n",
            "Quantized layer transformer.h.26.attn.c_proj with scale factor: 3.04e+02\n",
            "Processing layer: transformer.h.26.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.26.mlp.c_fc: -8.39\n",
            "Quantized layer transformer.h.26.mlp.c_fc with scale factor: 3.35e+02\n",
            "Processing layer: transformer.h.26.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.26.mlp.c_proj: -8.15\n",
            "Quantized layer transformer.h.26.mlp.c_proj with scale factor: 2.84e+02\n",
            "Processing layer: transformer.h.27.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.27.attn.c_attn: -8.27\n",
            "Quantized layer transformer.h.27.attn.c_attn with scale factor: 3.08e+02\n",
            "Processing layer: transformer.h.27.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.27.attn.c_proj: -8.38\n",
            "Quantized layer transformer.h.27.attn.c_proj with scale factor: 3.32e+02\n",
            "Processing layer: transformer.h.27.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.27.mlp.c_fc: -8.27\n",
            "Quantized layer transformer.h.27.mlp.c_fc with scale factor: 3.09e+02\n",
            "Processing layer: transformer.h.27.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.27.mlp.c_proj: -8.24\n",
            "Quantized layer transformer.h.27.mlp.c_proj with scale factor: 3.02e+02\n",
            "Processing layer: transformer.h.28.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.28.attn.c_attn: -8.34\n",
            "Quantized layer transformer.h.28.attn.c_attn with scale factor: 3.23e+02\n",
            "Processing layer: transformer.h.28.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.28.attn.c_proj: -8.26\n",
            "Quantized layer transformer.h.28.attn.c_proj with scale factor: 3.06e+02\n",
            "Processing layer: transformer.h.28.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.28.mlp.c_fc: -8.34\n",
            "Quantized layer transformer.h.28.mlp.c_fc with scale factor: 3.23e+02\n",
            "Processing layer: transformer.h.28.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.28.mlp.c_proj: -8.07\n",
            "Quantized layer transformer.h.28.mlp.c_proj with scale factor: 2.68e+02\n",
            "Processing layer: transformer.h.29.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.29.attn.c_attn: -8.38\n",
            "Quantized layer transformer.h.29.attn.c_attn with scale factor: 3.33e+02\n",
            "Processing layer: transformer.h.29.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.29.attn.c_proj: -8.20\n",
            "Quantized layer transformer.h.29.attn.c_proj with scale factor: 2.95e+02\n",
            "Processing layer: transformer.h.29.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.29.mlp.c_fc: -8.46\n",
            "Quantized layer transformer.h.29.mlp.c_fc with scale factor: 3.52e+02\n",
            "Processing layer: transformer.h.29.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.29.mlp.c_proj: -8.17\n",
            "Quantized layer transformer.h.29.mlp.c_proj with scale factor: 2.89e+02\n",
            "Processing layer: transformer.h.30.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.30.attn.c_attn: -8.46\n",
            "Quantized layer transformer.h.30.attn.c_attn with scale factor: 3.53e+02\n",
            "Processing layer: transformer.h.30.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.30.attn.c_proj: -8.10\n",
            "Quantized layer transformer.h.30.attn.c_proj with scale factor: 2.74e+02\n",
            "Processing layer: transformer.h.30.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.30.mlp.c_fc: -8.30\n",
            "Quantized layer transformer.h.30.mlp.c_fc with scale factor: 3.15e+02\n",
            "Processing layer: transformer.h.30.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.30.mlp.c_proj: -8.11\n",
            "Quantized layer transformer.h.30.mlp.c_proj with scale factor: 2.77e+02\n",
            "Processing layer: transformer.h.31.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.31.attn.c_attn: -8.19\n",
            "Quantized layer transformer.h.31.attn.c_attn with scale factor: 2.92e+02\n",
            "Processing layer: transformer.h.31.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.31.attn.c_proj: -8.11\n",
            "Quantized layer transformer.h.31.attn.c_proj with scale factor: 2.77e+02\n",
            "Processing layer: transformer.h.31.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.31.mlp.c_fc: -8.32\n",
            "Quantized layer transformer.h.31.mlp.c_fc with scale factor: 3.21e+02\n",
            "Processing layer: transformer.h.31.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.31.mlp.c_proj: -7.88\n",
            "Quantized layer transformer.h.31.mlp.c_proj with scale factor: 2.36e+02\n",
            "Processing layer: transformer.h.32.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.32.attn.c_attn: -8.22\n",
            "Quantized layer transformer.h.32.attn.c_attn with scale factor: 2.99e+02\n",
            "Processing layer: transformer.h.32.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.32.attn.c_proj: -8.29\n",
            "Quantized layer transformer.h.32.attn.c_proj with scale factor: 3.14e+02\n",
            "Processing layer: transformer.h.32.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.32.mlp.c_fc: -8.45\n",
            "Quantized layer transformer.h.32.mlp.c_fc with scale factor: 3.50e+02\n",
            "Processing layer: transformer.h.32.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.32.mlp.c_proj: -7.92\n",
            "Quantized layer transformer.h.32.mlp.c_proj with scale factor: 2.43e+02\n",
            "Processing layer: transformer.h.33.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.33.attn.c_attn: -8.43\n",
            "Quantized layer transformer.h.33.attn.c_attn with scale factor: 3.44e+02\n",
            "Processing layer: transformer.h.33.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.33.attn.c_proj: -8.30\n",
            "Quantized layer transformer.h.33.attn.c_proj with scale factor: 3.14e+02\n",
            "Processing layer: transformer.h.33.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.33.mlp.c_fc: -8.45\n",
            "Quantized layer transformer.h.33.mlp.c_fc with scale factor: 3.49e+02\n",
            "Processing layer: transformer.h.33.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.33.mlp.c_proj: -7.90\n",
            "Quantized layer transformer.h.33.mlp.c_proj with scale factor: 2.39e+02\n",
            "Processing layer: transformer.h.34.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.34.attn.c_attn: -8.32\n",
            "Quantized layer transformer.h.34.attn.c_attn with scale factor: 3.20e+02\n",
            "Processing layer: transformer.h.34.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.34.attn.c_proj: -8.15\n",
            "Quantized layer transformer.h.34.attn.c_proj with scale factor: 2.85e+02\n",
            "Processing layer: transformer.h.34.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.34.mlp.c_fc: -8.42\n",
            "Quantized layer transformer.h.34.mlp.c_fc with scale factor: 3.43e+02\n",
            "Processing layer: transformer.h.34.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.34.mlp.c_proj: -7.86\n",
            "Quantized layer transformer.h.34.mlp.c_proj with scale factor: 2.32e+02\n",
            "Processing layer: transformer.h.35.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.35.attn.c_attn: -8.54\n",
            "Quantized layer transformer.h.35.attn.c_attn with scale factor: 3.73e+02\n",
            "Processing layer: transformer.h.35.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.35.attn.c_proj: -8.32\n",
            "Quantized layer transformer.h.35.attn.c_proj with scale factor: 3.19e+02\n",
            "Processing layer: transformer.h.35.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.35.mlp.c_fc: -8.19\n",
            "Quantized layer transformer.h.35.mlp.c_fc with scale factor: 2.92e+02\n",
            "Processing layer: transformer.h.35.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.35.mlp.c_proj: -7.97\n",
            "Quantized layer transformer.h.35.mlp.c_proj with scale factor: 2.51e+02\n",
            "Processing layer: lm_head\n",
            "x_with_max_frequency for lm_head: -4.26\n",
            "Quantized layer lm_head with scale factor: 1.92e+01\n",
            "Total layers processed: 145\n",
            "MAC operation count: 772117760\n",
            "MAC operation count: 772117760\n",
            "Layer count: 145\n",
            "MAC operation count  772117760\n",
            "Layer count  145\n",
            "Machine learning is the study of for you you that type as table, example).\n",
            ". )\n",
            " e it is not you on\n",
            ")\n",
            " on the as the =.. for example of each. example\n",
            " example inof....\n",
            "-----------------\n",
            "Machine learning is the study of is.\n",
            " for a is also. n) ) a.\n",
            ".).\n",
            "_ n.\n",
            ".,.00.. } for a.\n",
            ".\n",
            ">\n",
            "..\n",
            " on = 0..\n",
            "-----------------------------------\n",
            "Machine learning is the study of. I like,. e.., C)\n",
            "\n",
            "\n",
            ".\n",
            ",.,\n",
            " with a,. on index.)\n",
            " 1 the,: et.,\n",
            "\n",
            "\n",
            "\n",
            ",.\n",
            ".. =\n",
            "-----------------------------------\n",
            "In the 19th century, the invention, theth anniversary of asth,?..us in 2017, in this fut, on\n",
            "us, on the as the,.. year? n\n",
            "-----------------\n",
            "In the 19th century, the invention.01?\n",
            "? ?\n",
            "-----------------------------------\n",
            "In the 19th century, the invention. in n n=\n",
            "-----------------------------------\n",
            "A robot was created for the be that created as the, are being. created in an e in the\n",
            " in this time space.\n",
            " the be the,.. created in n each time in each different in the. of the. of.\n",
            "-----------------\n",
            "A robot was created by by by for a and of by n)\n",
            " a by the. by\n",
            " of us that of.,. so.. that for the. we.\n",
            ". the the to ( for each. G., \n",
            "-----------------------------------\n",
            "A robot was created by the of, of the.. man was created by\n",
            ". Created by Alex. man with the each each of the each man. of the man:. the,\n",
            "\n",
            " no the man., were created that,,\n",
            "-----------------------------------\n",
            "One day I will for you be that day will be,? be the be in your Saturday morning morning be at night with Sunday at morning be Thursday will be.. for? what tomorrow be in each day be tomorrow.. be a afternoon.\n",
            "-----------------\n",
            "One day I will be Monday Monday for Monday night Friday night Saturday night Thursday Saturday Thursday Sunday Friday morning Thursday afternoon September Thursday afternoon Friday Friday. Wednesday afternoon Sunday Saturday Friday Wednesday Monday Tuesday. Friday Thursday morning Thursday Wednesday Friday Thursday Monday Thursday Monday Thursday afternoon Thursday\n",
            "-----------------------------------\n",
            "One day I will come I like, day Monday afternoon.? night afternoon. Monday morning morning. day. Saturday night morning Sunday. Monday morning. day! day tomorrow day Monday morning evening. morning! morning Thursday evening Monday morning. Sunday evening afternoon\n",
            "-----------------------------------\n",
            "\n",
            " FP32 ref : \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import set_seed\n",
        "from qtorch_plus.quant import posit_quantize, float_quantize, configurable_table_quantize\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "\n",
        "#final with 3 layers skipped :\n",
        "full_table = np.array([6.59179688e-03, 2.19726562e-02, 4.02832031e-02, 6.25000000e-02,\n",
        "                8.51440430e-02, 2.10937500e-01, 1.21093750e-01, 5.36407471e-01,\n",
        "                1.56250000e-02, 6.25000000e-02, 1.25000000e-01, 1.64062500e-01,\n",
        "                2.92968750e-01, 6.25000000e-01, 8.43750000e-01, 4.37500000e-01,\n",
        "                1.00000000e+00, 2.11486816e+00, 1.50000000e+00, 1.25000000e+00,\n",
        "                4.25000000e+00, 3.08789062e+00, 8.25000000e+00, 6.00000000e+00])\n",
        "\n",
        "weight_table = full_table[:8]\n",
        "act_table = full_table[8:]\n",
        "weight_table = np.sort(weight_table)\n",
        "act_table = np.sort(act_table)\n",
        "print (len(weight_table))\n",
        "print (weight_table)\n",
        "print (act_table)\n",
        "\n",
        "def linear_weight(input):\n",
        "    # return input\n",
        "    # return configurable_table_quantize(input, torch.tensor(weight_table,dtype = torch.float), scale= 1.0)\n",
        "    return posit_quantize(input,nsize=8, es=1, scale = 1)\n",
        "    # return float_quantize(input,exp=4, man=3, rounding=\"nearest\")\n",
        "\n",
        "def linear_activation(input):\n",
        "    # return input\n",
        "    # return configurable_table_quantize(input,torch.tensor(act_table, dtype=torch.float), scale= 1.0)\n",
        "    # return posit_quantize(input,nsize=6, es=0, scale = 1)\n",
        "    return float_quantize(input,exp=4, man=3, rounding=\"nearest\")\n",
        "\n",
        "def forward_pre_hook_linear(m, input):\n",
        "    return (linear_activation(input[0]),)\n",
        "\n",
        "model = model.to(device)\n",
        "layer_count = 0\n",
        "op_count = 0\n",
        "epsilon = 1e-12  # To avoid log(0)\n",
        "import transformers.modeling_utils as modeling_utils\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    # Check if the module is quantizable\n",
        "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear) or isinstance(module, modeling_utils.Conv1D):\n",
        "        layer_count += 1\n",
        "        print(f\"Processing layer: {name}\")\n",
        "\n",
        "        # Flatten the weights and compute log2 scale\n",
        "        weights_flattened = module.weight.data.cpu().numpy().flatten()\n",
        "        # ////////////////////////////////////////////////////////////\n",
        "        log2_weights = np.log2(np.abs(weights_flattened) + epsilon)\n",
        "        counts, bins = np.histogram(log2_weights, bins=100)\n",
        "        max_bin_index = np.argmax(counts)\n",
        "        x_with_max_frequency = (bins[max_bin_index] + bins[max_bin_index + 1]) / 2  # Bin center\n",
        "        print(f\"x_with_max_frequency for {name}: {x_with_max_frequency:.2f}\")\n",
        "        scale = 2 ** (-x_with_max_frequency)\n",
        "        # ////////////////////////////////////////////////////////////\n",
        "        quantized_weights = posit_quantize(torch.tensor(module.weight.data, dtype=torch.float32), nsize=4, es=0, scale=scale)\n",
        "        module.weight.data = quantized_weights\n",
        "\n",
        "        print(f\"Quantized layer {name} with scale factor: {scale:.2e}\")\n",
        "        module.register_forward_pre_hook(forward_pre_hook_linear)\n",
        "\n",
        "\n",
        "        # Count operations\n",
        "        if isinstance(module, modeling_utils.Conv1D):\n",
        "            op_count += module.weight.shape[0] * module.weight.shape[1]\n",
        "        else:\n",
        "            op_count += module.in_features * module.out_features\n",
        "\n",
        "    # Handle embeddings separately\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "        print(f\"Processing embedding layer: {name}\")\n",
        "\n",
        "        # Flatten the weights and compute log2 scale\n",
        "        weights_flattened = module.weight.data.cpu().numpy().flatten()\n",
        "        log2_weights = np.log2(np.abs(weights_flattened) + epsilon)\n",
        "\n",
        "        # Compute histogram and find the bin with the maximum frequency\n",
        "        counts, bins = np.histogram(log2_weights, bins=100)\n",
        "        max_bin_index = np.argmax(counts)\n",
        "        x_with_max_frequency = (bins[max_bin_index] + bins[max_bin_index + 1]) / 2  # Bin center\n",
        "        print(f\"x_with_max_frequency for {name}: {x_with_max_frequency:.2f}\")\n",
        "\n",
        "        # Apply quantization with scale based on x_with_max_frequency\n",
        "        scale = 2 ** (-x_with_max_frequency)\n",
        "        quantized_weights = posit_quantize(torch.tensor(module.weight.data, dtype=torch.float32), nsize=4, es=0, scale=scale)\n",
        "        module.weight.data = quantized_weights\n",
        "\n",
        "        print(f\"Quantized embedding layer {name} with scale factor: {scale:.2e}\")\n",
        "\n",
        "print(\"Total layers processed:\", layer_count)\n",
        "print(\"MAC operation count:\", op_count)\n",
        "\n",
        "print(\"MAC operation count:\", op_count)\n",
        "print(\"Layer count:\", layer_count)\n",
        "\n",
        "print (\"MAC operation count \", op_count)\n",
        "print (\"Layer count \", layer_count)\n",
        "\n",
        "\n",
        "# from nlp import load_dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "test = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
        "encodings = tokenizer('\\n\\n'.join(test['text']), return_tensors='pt')\n",
        "#model = model.to(device)\n",
        "def generate_text(model_new):\n",
        "  text_generation = pipeline(\"text-generation\", model=model_new, tokenizer=tokenizer, device = 0)\n",
        "  #set_seed(42)\n",
        "  prefix_texts = [\"Machine learning is the study of\",\n",
        "                    \"In the 19th century, the invention\",\n",
        "                    \"A robot was created\",\n",
        "                    \"One day I will\"\n",
        "                  ]\n",
        "  for prefix_text in prefix_texts:\n",
        "    #generated_text= text_generation(prefix_text, max_length=50, do_sample=False )[0]\n",
        "    set_seed(42)\n",
        "    generated_text= text_generation(prefix_text, max_length=50, num_return_sequences=3)\n",
        "    print(generated_text[0]['generated_text'])\n",
        "    print (\"-----------------\")\n",
        "    print(generated_text[1]['generated_text'])\n",
        "    print (\"-----------------------------------\")\n",
        "    print(generated_text[2]['generated_text'])\n",
        "    print (\"-----------------------------------\")\n",
        "generate_text(model)\n",
        "\n",
        "print (\"\\n FP32 ref : \\n\")\n",
        "# model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
        "# generate_text(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTsr8P3cvri2",
        "outputId": "66119382-262a-4de5-edee-1e2094f29e7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input size: 287644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 281/281 [01:34<00:00,  2.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity: 23.910572052001953\n"
          ]
        }
      ],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "max_length = model.config.n_positions\n",
        "stride = 1024\n",
        "\n",
        "lls = []\n",
        "input_size = encodings.input_ids.size(1)\n",
        "print(\"Input size:\", input_size)\n",
        "\n",
        "for i in tqdm(range(0, input_size, stride)):\n",
        "    begin_loc = max(i + stride - max_length, 0)\n",
        "    end_loc = min(i + stride, input_size)\n",
        "    trg_len = end_loc - i\n",
        "\n",
        "    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
        "    target_ids = input_ids.clone()\n",
        "    target_ids[:, :-trg_len] = -100\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=target_ids)\n",
        "        log_likelihood = outputs[0] * trg_len\n",
        "        # print(f\"Log Likelihood for step {i}: {log_likelihood}\")\n",
        "\n",
        "    lls.append(log_likelihood)\n",
        "\n",
        "if lls:  # Ensure lls is not empty\n",
        "    ppl = torch.exp(torch.stack(lls).sum() / input_size)\n",
        "    print(\"Perplexity:\", ppl.item())\n",
        "else:\n",
        "    print(\"No log likelihoods calculated.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "posit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00739f8e753d4f7cb7a11ad8ef98184d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbaf4bd3655f49e5afa3e85c23429054",
            "placeholder": "",
            "style": "IPY_MODEL_8579e8bcea83406287627c31c49ee4b3",
            "value": "vocab.json:100%"
          }
        },
        "00ad030852364c5d9a91c791967b579a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c538629f4cc442bcb3b43d0a0bf58865",
              "IPY_MODEL_b7f9d65a2a424b96942d421156932b39",
              "IPY_MODEL_ebc1e222709342ab81e7e49f3d6e58f0"
            ],
            "layout": "IPY_MODEL_b5b8259396944af190739387c4f3e987"
          }
        },
        "01ea0430af0b47ebbb292b97c7fa00ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "062f41eb2a1046808f65ea6e440f0df3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2e53cdddc142fd915c9309e98f570b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c02b7a8f028544f9ba49d1836a31ce2f",
              "IPY_MODEL_840cf52790c14b98ad50643f0be8e297",
              "IPY_MODEL_5f3bda09bbf3411292b41f380522bd2a"
            ],
            "layout": "IPY_MODEL_c4ce3eb5761f4fd9a9b6293800994570"
          }
        },
        "0fc0d243561544709472a6d171374909": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "150b806ba66b47dfb8fb3f2e941502ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "225c77726c2443cf9907c6f342dc6989": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23ce38918cc34c3fb6afff61502766a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ea1aaefd7244388b0af89fcf3defa7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27e0c123bafd44579e1ec77a17888b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2debd06b648343dd9c3d2e2793c9f5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ad620366684e3aafd65ca4fe9d3837": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "373a4c4089414f5cb857d63e269dd336": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382f254a57ce4da5a0ecd9b291395669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3aa7601c692144b6afe29aac12ea4a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a777e8f71424286bafbaee44d6298dd",
            "placeholder": "",
            "style": "IPY_MODEL_887f8c6577624e468aeedd5e0719ed47",
            "value": "1.36M/1.36M[00:00&lt;00:00,13.3MB/s]"
          }
        },
        "3eb48787e3b04faea1b39441977cb032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69204362e6ef4678971d614fb0686aca",
            "placeholder": "",
            "style": "IPY_MODEL_27e0c123bafd44579e1ec77a17888b24",
            "value": "26.0/26.0[00:00&lt;00:00,1.93kB/s]"
          }
        },
        "3fddcc80d6224dbb9c8d12818652f293": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43e9937624404bebbd8101130f140bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44e97f109e534534b04598f341bd086b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01ea0430af0b47ebbb292b97c7fa00ce",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebb54ddafa244e4da5263217e36e089c",
            "value": 26
          }
        },
        "4574302ffe6344cda2db49aa4799c90f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51adb325cf614081ac5e83b62313bc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eac5cd46cda34846869a1ab8ba750139",
              "IPY_MODEL_ffde35caf0c441c5bc2cf3253753b970",
              "IPY_MODEL_3aa7601c692144b6afe29aac12ea4a93"
            ],
            "layout": "IPY_MODEL_987ffebd2fbb4491925236934a425ecb"
          }
        },
        "560f75060fc845959bbe92a3e9e10cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f3bda09bbf3411292b41f380522bd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_912ffd0281cb44dfb011ce1d9117dff9",
            "placeholder": "",
            "style": "IPY_MODEL_b13827923c7a4a01b81254c069ea3c2d",
            "value": "456k/456k[00:00&lt;00:00,5.63MB/s]"
          }
        },
        "691ee1705e06443e96711cbef3140736": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90f92d26cc6f44da8bfa93ba123b13e1",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_382f254a57ce4da5a0ecd9b291395669",
            "value": 1042301
          }
        },
        "69204362e6ef4678971d614fb0686aca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a777e8f71424286bafbaee44d6298dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7522cb91f9294e048895b0271a8950b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78404c0b802e4e9c89a49859ab6406e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6dae690b8964dc4b7270bcd31d6af37",
              "IPY_MODEL_8441693459d0482dbafb27ba6e532fcc",
              "IPY_MODEL_8279318bbd8e40699e4b9b3db3e1feea"
            ],
            "layout": "IPY_MODEL_79a60ae742c24c379d54e59dc0ef7d8c"
          }
        },
        "79a60ae742c24c379d54e59dc0ef7d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8110dd23c8024748a1200a6f002a4feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8279318bbd8e40699e4b9b3db3e1feea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ce38918cc34c3fb6afff61502766a2",
            "placeholder": "",
            "style": "IPY_MODEL_f41d1255fa1740478ccdd55465546315",
            "value": "124/124[00:00&lt;00:00,7.49kB/s]"
          }
        },
        "82f17d89785944af95b20cc3af2f138a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83cf1f99cdfb47e98dfd30f7b6660936": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4574302ffe6344cda2db49aa4799c90f",
            "max": 3247159078,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_225c77726c2443cf9907c6f342dc6989",
            "value": 3247159078
          }
        },
        "840cf52790c14b98ad50643f0be8e297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53a1b3b4b18495c99a11e5f39d396eb",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed9f7a93361c45d1bc18890c4b355766",
            "value": 456318
          }
        },
        "8441693459d0482dbafb27ba6e532fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ae0017ab8c4ef899693f54a572cbb8",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_150b806ba66b47dfb8fb3f2e941502ea",
            "value": 124
          }
        },
        "8579e8bcea83406287627c31c49ee4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "887f8c6577624e468aeedd5e0719ed47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dff12e8a5844b538c907310f6d1a595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fbcb321cd3247ccb77b9fa3807982dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90f92d26cc6f44da8bfa93ba123b13e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "912ffd0281cb44dfb011ce1d9117dff9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96631b351a46456abe8267156ace46e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "987ffebd2fbb4491925236934a425ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41b135f629f441292511e486547525a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e474c5a4f3024f709a08e8287218ba8f",
              "IPY_MODEL_44e97f109e534534b04598f341bd086b",
              "IPY_MODEL_3eb48787e3b04faea1b39441977cb032"
            ],
            "layout": "IPY_MODEL_43e9937624404bebbd8101130f140bdc"
          }
        },
        "af9d5f752d0c4116b8f8a5ef96991961": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8d828ebbbfb4f2b840cac7cebc1e8c6",
              "IPY_MODEL_83cf1f99cdfb47e98dfd30f7b6660936",
              "IPY_MODEL_e9d602a86e8f49b189ef4c306ae2f628"
            ],
            "layout": "IPY_MODEL_373a4c4089414f5cb857d63e269dd336"
          }
        },
        "b13827923c7a4a01b81254c069ea3c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3534fdd71364144a9f4d270c18b028d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5b8259396944af190739387c4f3e987": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f9d65a2a424b96942d421156932b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde7244069be49fab5489502a5c00389",
            "max": 666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c28630d899bb4e6992860b3e93bf515e",
            "value": 666
          }
        },
        "c006b510a3cb43c5a2d8e33776ffbf5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c009bb702dbb42a8a390492e611de786": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02b7a8f028544f9ba49d1836a31ce2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3534fdd71364144a9f4d270c18b028d",
            "placeholder": "",
            "style": "IPY_MODEL_8dff12e8a5844b538c907310f6d1a595",
            "value": "merges.txt:100%"
          }
        },
        "c0ee4f7c6ad944fea9b42c3ab8fb175a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c28630d899bb4e6992860b3e93bf515e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2ae0017ab8c4ef899693f54a572cbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ce3eb5761f4fd9a9b6293800994570": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c538629f4cc442bcb3b43d0a0bf58865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d245544116bc41939980a2dd1291859f",
            "placeholder": "",
            "style": "IPY_MODEL_0fc0d243561544709472a6d171374909",
            "value": "config.json:100%"
          }
        },
        "c53a1b3b4b18495c99a11e5f39d396eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d828ebbbfb4f2b840cac7cebc1e8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c009bb702dbb42a8a390492e611de786",
            "placeholder": "",
            "style": "IPY_MODEL_33ad620366684e3aafd65ca4fe9d3837",
            "value": "model.safetensors:100%"
          }
        },
        "cbaf4bd3655f49e5afa3e85c23429054": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde7244069be49fab5489502a5c00389": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0d05fbf1df49d6bf6fd7a729b3a014": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d245544116bc41939980a2dd1291859f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69b05587cf64f60a8e7f8b42c3ee47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ea1aaefd7244388b0af89fcf3defa7",
            "placeholder": "",
            "style": "IPY_MODEL_c0ee4f7c6ad944fea9b42c3ab8fb175a",
            "value": "1.04M/1.04M[00:00&lt;00:00,5.49MB/s]"
          }
        },
        "e474c5a4f3024f709a08e8287218ba8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2debd06b648343dd9c3d2e2793c9f5bf",
            "placeholder": "",
            "style": "IPY_MODEL_560f75060fc845959bbe92a3e9e10cdc",
            "value": "tokenizer_config.json:100%"
          }
        },
        "e52fae3f086b45a1b4ee9f8de1da72ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e87e99711e224653900bdf4f5a46e340": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d602a86e8f49b189ef4c306ae2f628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e87e99711e224653900bdf4f5a46e340",
            "placeholder": "",
            "style": "IPY_MODEL_96631b351a46456abe8267156ace46e5",
            "value": "3.25G/3.25G[00:20&lt;00:00,250MB/s]"
          }
        },
        "eac5cd46cda34846869a1ab8ba750139": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e52fae3f086b45a1b4ee9f8de1da72ae",
            "placeholder": "",
            "style": "IPY_MODEL_7522cb91f9294e048895b0271a8950b0",
            "value": "tokenizer.json:100%"
          }
        },
        "ebb54ddafa244e4da5263217e36e089c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebc1e222709342ab81e7e49f3d6e58f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_062f41eb2a1046808f65ea6e440f0df3",
            "placeholder": "",
            "style": "IPY_MODEL_82f17d89785944af95b20cc3af2f138a",
            "value": "666/666[00:00&lt;00:00,22.9kB/s]"
          }
        },
        "ed9f7a93361c45d1bc18890c4b355766": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f41d1255fa1740478ccdd55465546315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6dae690b8964dc4b7270bcd31d6af37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c006b510a3cb43c5a2d8e33776ffbf5f",
            "placeholder": "",
            "style": "IPY_MODEL_ce0d05fbf1df49d6bf6fd7a729b3a014",
            "value": "generation_config.json:100%"
          }
        },
        "fce111d5fb084d369dbef665f0bda3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00739f8e753d4f7cb7a11ad8ef98184d",
              "IPY_MODEL_691ee1705e06443e96711cbef3140736",
              "IPY_MODEL_d69b05587cf64f60a8e7f8b42c3ee47b"
            ],
            "layout": "IPY_MODEL_8fbcb321cd3247ccb77b9fa3807982dd"
          }
        },
        "ffde35caf0c441c5bc2cf3253753b970": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fddcc80d6224dbb9c8d12818652f293",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8110dd23c8024748a1200a6f002a4feb",
            "value": 1355256
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
