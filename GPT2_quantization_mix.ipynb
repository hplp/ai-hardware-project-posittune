{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVEKHkvBS8iy",
        "outputId": "458a58da-c017-47d9-c313-2b4dd83d1fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generating table for 2^(I.F), I=2, F=1 \n",
            "power 2 table:  [-4.0, -3.5, -3.0, -2.5, -2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
            "system 2^(2.1):  [0.0625, 0.08838834764831845, 0.125, 0.1767766952966369, 0.25, 0.3535533905932738, 0.5, 0.7071067811865476, 1.0, 1.4142135623730951, 2.0, 2.8284271247461903, 4.0, 5.656854249492381, 8.0, 11.313708498984761]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_log2system(int_length, fraction_length):\n",
        "  #system 2^(I.F)\n",
        "  print (\"generating table for 2^(I.F), I=%d, F=%d \"%(int_length,fraction_length))\n",
        "  step  =  2**(-fraction_length)\n",
        "  power_table = np.arange(-2**int_length,  2**int_length, step)\n",
        "  print (\"power 2 table: \", list(power_table))\n",
        "  table = list(map(lambda x: 2.0**x, power_table))\n",
        "  print (\"system 2^(%d.%d): \"%(int_length,fraction_length), table)\n",
        "  return table\n",
        "\n",
        "weight_table = generate_log2system(2,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R89-lb3TB1O",
        "outputId": "9b8414b0-39fd-4a20-8a09-6f9ab5ced0dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 19 23:41:22 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting nlp\n",
            "  Downloading nlp-0.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nlp) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from nlp) (17.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from nlp) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nlp) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from nlp) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from nlp) (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from nlp) (3.16.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from nlp) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->nlp) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->nlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->nlp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->nlp) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->nlp) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nlp) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->nlp) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->nlp) (1.16.0)\n",
            "Downloading nlp-0.4.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nlp\n",
            "Successfully installed nlp-0.4.0\n",
            "Cloning into 'QPyTorch'...\n",
            "remote: Enumerating objects: 1698, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 1698 (delta 81), reused 64 (delta 55), pack-reused 1593 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1698/1698), 798.38 KiB | 16.29 MiB/s, done.\n",
            "Resolving deltas: 100% (1121/1121), done.\n",
            "Branch 'posit-constant-generation' set up to track remote branch 'posit-constant-generation' from 'origin'.\n",
            "Switched to a new branch 'posit-constant-generation'\n",
            "Processing /content/QPyTorch\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from qtorch==0.2.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.2.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.2.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.2.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.2.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.2.0) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.2.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.5.0->qtorch==0.2.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->qtorch==0.2.0) (3.0.2)\n",
            "Building wheels for collected packages: qtorch\n",
            "  Building wheel for qtorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qtorch: filename=qtorch-0.2.0-py3-none-any.whl size=34608 sha256=fe9f1e8bf0c8e624a30f054968e7a47ab8bd6437b7bff06d02a0377a043b1ec4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nh8tets6/wheels/f5/0e/54/8b19b6069375f0328fd919e6ec6ac2259db6a30ffdec610b11\n",
            "Successfully built qtorch\n",
            "Installing collected packages: qtorch\n",
            "Successfully installed qtorch-0.2.0\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!nvidia-smi\n",
        "!pip install transformers datasets\n",
        "!pip install nlp\n",
        "\n",
        "!git clone https://github.com/minhhn2910/QPyTorch\n",
        "try:\n",
        "  os.chdir('/content/QPyTorch')\n",
        "except:\n",
        "  pass\n",
        "!git checkout posit-constant-generation\n",
        "\n",
        "!pip install ./\n",
        "!pip install ninja\n",
        "\n",
        "try:\n",
        "  os.chdir('/content/')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  raise RuntimeError('Cannot run this cell without GPU runtime.')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "device = 'cuda'\n",
        "model_id = 'gpt2-large'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_id)\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
        "# Print all layer names\n",
        "print(\"Listing all layers in the model:\")\n",
        "for name, module in model.named_modules():\n",
        "    print(name, \":\", type(module))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "00ad030852364c5d9a91c791967b579a",
            "c538629f4cc442bcb3b43d0a0bf58865",
            "b7f9d65a2a424b96942d421156932b39",
            "ebc1e222709342ab81e7e49f3d6e58f0",
            "b5b8259396944af190739387c4f3e987",
            "d245544116bc41939980a2dd1291859f",
            "0fc0d243561544709472a6d171374909",
            "cde7244069be49fab5489502a5c00389",
            "c28630d899bb4e6992860b3e93bf515e",
            "062f41eb2a1046808f65ea6e440f0df3",
            "82f17d89785944af95b20cc3af2f138a",
            "af9d5f752d0c4116b8f8a5ef96991961",
            "c8d828ebbbfb4f2b840cac7cebc1e8c6",
            "83cf1f99cdfb47e98dfd30f7b6660936",
            "e9d602a86e8f49b189ef4c306ae2f628",
            "373a4c4089414f5cb857d63e269dd336",
            "c009bb702dbb42a8a390492e611de786",
            "33ad620366684e3aafd65ca4fe9d3837",
            "4574302ffe6344cda2db49aa4799c90f",
            "225c77726c2443cf9907c6f342dc6989",
            "e87e99711e224653900bdf4f5a46e340",
            "96631b351a46456abe8267156ace46e5",
            "78404c0b802e4e9c89a49859ab6406e3",
            "f6dae690b8964dc4b7270bcd31d6af37",
            "8441693459d0482dbafb27ba6e532fcc",
            "8279318bbd8e40699e4b9b3db3e1feea",
            "79a60ae742c24c379d54e59dc0ef7d8c",
            "c006b510a3cb43c5a2d8e33776ffbf5f",
            "ce0d05fbf1df49d6bf6fd7a729b3a014",
            "c2ae0017ab8c4ef899693f54a572cbb8",
            "150b806ba66b47dfb8fb3f2e941502ea",
            "23ce38918cc34c3fb6afff61502766a2",
            "f41d1255fa1740478ccdd55465546315",
            "a41b135f629f441292511e486547525a",
            "e474c5a4f3024f709a08e8287218ba8f",
            "44e97f109e534534b04598f341bd086b",
            "3eb48787e3b04faea1b39441977cb032",
            "43e9937624404bebbd8101130f140bdc",
            "2debd06b648343dd9c3d2e2793c9f5bf",
            "560f75060fc845959bbe92a3e9e10cdc",
            "01ea0430af0b47ebbb292b97c7fa00ce",
            "ebb54ddafa244e4da5263217e36e089c",
            "69204362e6ef4678971d614fb0686aca",
            "27e0c123bafd44579e1ec77a17888b24",
            "fce111d5fb084d369dbef665f0bda3fe",
            "00739f8e753d4f7cb7a11ad8ef98184d",
            "691ee1705e06443e96711cbef3140736",
            "d69b05587cf64f60a8e7f8b42c3ee47b",
            "8fbcb321cd3247ccb77b9fa3807982dd",
            "cbaf4bd3655f49e5afa3e85c23429054",
            "8579e8bcea83406287627c31c49ee4b3",
            "90f92d26cc6f44da8bfa93ba123b13e1",
            "382f254a57ce4da5a0ecd9b291395669",
            "26ea1aaefd7244388b0af89fcf3defa7",
            "c0ee4f7c6ad944fea9b42c3ab8fb175a",
            "0e2e53cdddc142fd915c9309e98f570b",
            "c02b7a8f028544f9ba49d1836a31ce2f",
            "840cf52790c14b98ad50643f0be8e297",
            "5f3bda09bbf3411292b41f380522bd2a",
            "c4ce3eb5761f4fd9a9b6293800994570",
            "b3534fdd71364144a9f4d270c18b028d",
            "8dff12e8a5844b538c907310f6d1a595",
            "c53a1b3b4b18495c99a11e5f39d396eb",
            "ed9f7a93361c45d1bc18890c4b355766",
            "912ffd0281cb44dfb011ce1d9117dff9",
            "b13827923c7a4a01b81254c069ea3c2d",
            "51adb325cf614081ac5e83b62313bc56",
            "eac5cd46cda34846869a1ab8ba750139",
            "ffde35caf0c441c5bc2cf3253753b970",
            "3aa7601c692144b6afe29aac12ea4a93",
            "987ffebd2fbb4491925236934a425ecb",
            "e52fae3f086b45a1b4ee9f8de1da72ae",
            "7522cb91f9294e048895b0271a8950b0",
            "3fddcc80d6224dbb9c8d12818652f293",
            "8110dd23c8024748a1200a6f002a4feb",
            "6a777e8f71424286bafbaee44d6298dd",
            "887f8c6577624e468aeedd5e0719ed47"
          ]
        },
        "id": "hyS_3JS5vkUz",
        "outputId": "664ad443-ae64-4186-c5ca-c45a4519aab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00ad030852364c5d9a91c791967b579a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af9d5f752d0c4116b8f8a5ef96991961"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78404c0b802e4e9c89a49859ab6406e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a41b135f629f441292511e486547525a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fce111d5fb084d369dbef665f0bda3fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e2e53cdddc142fd915c9309e98f570b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51adb325cf614081ac5e83b62313bc56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing all layers in the model:\n",
            " : <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
            "transformer : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n",
            "transformer.wte : <class 'torch.nn.modules.sparse.Embedding'>\n",
            "transformer.wpe : <class 'torch.nn.modules.sparse.Embedding'>\n",
            "transformer.drop : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h : <class 'torch.nn.modules.container.ModuleList'>\n",
            "transformer.h.0 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.0.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.0.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.0.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.0.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.0.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.0.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.0.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.0.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.1 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.1.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.1.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.1.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.1.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.1.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.1.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.1.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.1.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.2 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.2.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.2.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.2.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.2.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.2.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.2.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.2.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.2.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.3 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.3.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.3.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.3.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.3.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.3.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.3.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.3.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.3.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.4 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.4.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.4.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.4.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.4.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.4.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.4.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.4.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.4.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.5 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.5.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.5.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.5.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.5.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.5.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.5.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.5.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.5.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.6 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.6.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.6.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.6.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.6.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.6.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.6.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.6.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.6.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.7 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.7.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.7.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.7.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.7.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.7.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.7.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.7.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.7.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.8 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.8.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.8.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.8.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.8.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.8.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.8.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.8.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.8.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.9 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.9.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.9.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.9.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.9.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.9.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.9.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.9.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.9.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.10 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.10.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.10.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.10.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.10.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.10.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.10.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.10.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.10.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.11 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.11.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.11.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.11.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.11.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.11.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.11.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.11.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.11.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.12 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.12.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.12.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.12.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.12.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.12.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.12.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.12.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.12.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.12.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.12.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.12.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.12.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.13 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.13.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.13.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.13.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.13.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.13.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.13.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.13.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.13.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.13.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.13.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.13.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.13.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.14 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.14.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.14.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.14.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.14.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.14.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.14.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.14.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.14.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.14.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.14.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.14.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.14.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.15 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.15.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.15.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.15.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.15.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.15.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.15.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.15.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.15.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.15.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.15.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.15.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.15.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.16 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.16.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.16.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.16.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.16.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.16.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.16.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.16.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.16.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.16.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.16.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.16.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.16.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.17 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.17.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.17.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.17.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.17.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.17.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.17.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.17.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.17.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.17.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.17.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.17.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.17.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.18 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.18.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.18.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.18.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.18.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.18.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.18.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.18.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.18.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.18.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.18.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.18.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.18.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.19 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.19.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.19.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.19.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.19.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.19.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.19.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.19.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.19.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.19.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.19.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.19.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.19.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.20 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.20.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.20.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.20.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.20.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.20.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.20.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.20.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.20.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.20.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.20.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.20.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.20.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.21 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.21.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.21.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.21.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.21.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.21.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.21.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.21.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.21.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.21.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.21.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.21.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.21.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.22 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.22.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.22.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.22.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.22.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.22.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.22.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.22.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.22.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.22.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.22.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.22.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.22.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.23 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.23.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.23.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.23.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.23.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.23.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.23.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.23.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.23.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.23.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.23.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.23.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.23.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.24 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.24.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.24.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.24.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.24.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.24.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.24.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.24.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.24.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.24.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.24.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.24.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.24.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.25 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.25.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.25.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.25.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.25.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.25.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.25.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.25.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.25.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.25.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.25.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.25.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.25.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.26 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.26.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.26.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.26.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.26.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.26.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.26.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.26.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.26.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.26.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.26.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.26.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.26.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.27 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.27.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.27.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.27.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.27.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.27.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.27.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.27.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.27.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.27.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.27.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.27.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.27.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.28 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.28.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.28.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.28.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.28.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.28.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.28.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.28.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.28.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.28.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.28.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.28.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.28.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.29 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.29.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.29.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.29.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.29.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.29.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.29.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.29.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.29.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.29.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.29.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.29.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.29.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.30 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.30.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.30.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.30.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.30.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.30.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.30.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.30.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.30.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.30.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.30.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.30.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.30.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.31 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.31.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.31.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.31.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.31.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.31.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.31.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.31.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.31.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.31.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.31.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.31.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.31.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.32 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.32.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.32.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.32.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.32.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.32.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.32.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.32.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.32.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.32.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.32.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.32.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.32.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.33 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.33.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.33.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.33.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.33.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.33.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.33.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.33.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.33.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.33.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.33.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.33.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.33.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.34 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.34.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.34.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.34.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.34.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.34.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.34.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.34.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.34.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.34.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.34.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.34.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.34.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.35 : <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
            "transformer.h.35.ln_1 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.35.attn : <class 'transformers.models.gpt2.modeling_gpt2.GPT2SdpaAttention'>\n",
            "transformer.h.35.attn.c_attn : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.35.attn.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.35.attn.attn_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.35.attn.resid_dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.35.ln_2 : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.h.35.mlp : <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.35.mlp.c_fc : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.35.mlp.c_proj : <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.35.mlp.act : <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.35.mlp.dropout : <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.ln_f : <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "lm_head : <class 'torch.nn.modules.linear.Linear'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import set_seed\n",
        "from qtorch.quant import posit_quantize, float_quantize, configurable_table_quantize\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "\n",
        "#final with 3 layers skipped :\n",
        "full_table = np.array([6.59179688e-03, 2.19726562e-02, 4.02832031e-02, 6.25000000e-02,\n",
        "                8.51440430e-02, 2.10937500e-01, 1.21093750e-01, 5.36407471e-01,\n",
        "                1.56250000e-02, 6.25000000e-02, 1.25000000e-01, 1.64062500e-01,\n",
        "                2.92968750e-01, 6.25000000e-01, 8.43750000e-01, 4.37500000e-01,\n",
        "                1.00000000e+00, 2.11486816e+00, 1.50000000e+00, 1.25000000e+00,\n",
        "                4.25000000e+00, 3.08789062e+00, 8.25000000e+00, 6.00000000e+00])\n",
        "\n",
        "weight_table = full_table[:8]\n",
        "act_table = full_table[8:]\n",
        "weight_table = np.sort(weight_table)\n",
        "act_table = np.sort(act_table)\n",
        "print (len(weight_table))\n",
        "print (weight_table)\n",
        "print (act_table)\n",
        "\n",
        "def linear_weight(input):\n",
        "    # return input\n",
        "    # return configurable_table_quantize(input, torch.tensor(weight_table,dtype = torch.float), scale= 1.0)\n",
        "    return posit_quantize(input,nsize=8, es=1, scale = 1)\n",
        "    # return float_quantize(input,exp=4, man=3, rounding=\"nearest\")\n",
        "\n",
        "def linear_activation(input):\n",
        "    # return input\n",
        "    # return configurable_table_quantize(input,torch.tensor(act_table, dtype=torch.float), scale= 1.0)\n",
        "    return posit_quantize(input,nsize=6, es=0, scale = 1)\n",
        "    # return float_quantize(input,exp=4, man=3, rounding=\"nearest\")\n",
        "\n",
        "def forward_pre_hook_linear(m, input):\n",
        "    return (linear_activation(input[0]),)\n",
        "\n",
        "# model = model.to(device)\n",
        "# layer_count = 0\n",
        "# linear_layer_count = 0\n",
        "# op_count = 0\n",
        "# epsilon = 1e-12  # To avoid log(0)\n",
        "# import transformers.modeling_utils as  modeling_utils\n",
        "\n",
        "# for name, module in model.named_modules():\n",
        "#     # Check if the module is quantizable\n",
        "#     if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear) or isinstance(module, modeling_utils.Conv1D):\n",
        "#         layer_count += 1\n",
        "\n",
        "#         # Apply different quantization configurations for specific layers\n",
        "#         if name == \"transformer.h.0.attn.c_attn\":\n",
        "#             print(f\"Quantizing layer {name} with Posit<8,1>\")\n",
        "#             module.weight.data = posit_quantize(module.weight.data, nsize=8, es=1)\n",
        "#         elif name == \"transformer.h.1.attn.c_attn\":\n",
        "#             print(f\"Quantizing layer {name} with Posit<16,2>\")\n",
        "#             module.weight.data = posit_quantize(module.weight.data, nsize=16, es=2)\n",
        "#         elif name == \"transformer.h.2.attn.c_attn\":\n",
        "#             print(f\"Quantizing layer {name} with Float<4,3>\")\n",
        "#             module.weight.data = float_quantize(module.weight.data, exp=4, man=3, rounding=\"nearest\")\n",
        "#         else:\n",
        "#             # Default quantization\n",
        "#             print(f\"Quantizing layer {name} with default Posit<8,1>\")\n",
        "#             module.weight.data = posit_quantize(module.weight.data, nsize=8, es=1)\n",
        "\n",
        "#         # Register forward pre-hook for activations\n",
        "#         module.register_forward_pre_hook(forward_pre_hook_linear)\n",
        "\n",
        "#         # Count operations\n",
        "#         if isinstance(module, modeling_utils.Conv1D):\n",
        "#             op_count += module.weight.shape[0] * module.weight.shape[1]\n",
        "#         else:\n",
        "#             op_count += module.in_features * module.out_features\n",
        "\n",
        "#     # Handle embeddings separately\n",
        "#     elif isinstance(module, nn.Embedding):\n",
        "#         print(f\"Quantizing embedding layer {name} with Posit<8,1>\")\n",
        "#         module.weight.data = posit_quantize(module.weight.data, nsize=8, es=1)\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "layer_count = 0\n",
        "op_count = 0\n",
        "epsilon = 1e-12  # To avoid log(0)\n",
        "import transformers.modeling_utils as modeling_utils\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    # Check if the module is quantizable\n",
        "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear) or isinstance(module, modeling_utils.Conv1D):\n",
        "        layer_count += 1\n",
        "        print(f\"Processing layer: {name}\")\n",
        "\n",
        "        # Flatten the weights and compute log2 scale\n",
        "        weights_flattened = module.weight.data.cpu().numpy().flatten()\n",
        "        # ////////////////////////////////////////////////////////////\n",
        "        log2_weights = np.log2(np.abs(weights_flattened) + epsilon)\n",
        "        counts, bins = np.histogram(log2_weights, bins=100)\n",
        "        max_bin_index = np.argmax(counts)\n",
        "        x_with_max_frequency = (bins[max_bin_index] + bins[max_bin_index + 1]) / 2  # Bin center\n",
        "        print(f\"x_with_max_frequency for {name}: {x_with_max_frequency:.2f}\")\n",
        "        scale = 2 ** (-x_with_max_frequency)\n",
        "        # ////////////////////////////////////////////////////////////\n",
        "        quantized_weights = posit_quantize(torch.tensor(module.weight.data, dtype=torch.float32), nsize=6, es=0, scale=scale)\n",
        "        module.weight.data = quantized_weights\n",
        "\n",
        "        print(f\"Quantized layer {name} with scale factor: {scale:.2e}\")\n",
        "        module.register_forward_pre_hook(forward_pre_hook_linear)\n",
        "\n",
        "\n",
        "        # Count operations\n",
        "        if isinstance(module, modeling_utils.Conv1D):\n",
        "            op_count += module.weight.shape[0] * module.weight.shape[1]\n",
        "        else:\n",
        "            op_count += module.in_features * module.out_features\n",
        "\n",
        "    # Handle embeddings separately\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "        print(f\"Processing embedding layer: {name}\")\n",
        "\n",
        "        # Flatten the weights and compute log2 scale\n",
        "        weights_flattened = module.weight.data.cpu().numpy().flatten()\n",
        "        log2_weights = np.log2(np.abs(weights_flattened) + epsilon)\n",
        "\n",
        "        # Compute histogram and find the bin with the maximum frequency\n",
        "        counts, bins = np.histogram(log2_weights, bins=100)\n",
        "        max_bin_index = np.argmax(counts)\n",
        "        x_with_max_frequency = (bins[max_bin_index] + bins[max_bin_index + 1]) / 2  # Bin center\n",
        "        print(f\"x_with_max_frequency for {name}: {x_with_max_frequency:.2f}\")\n",
        "\n",
        "        # Apply quantization with scale based on x_with_max_frequency\n",
        "        scale = 2 ** (-x_with_max_frequency)\n",
        "        quantized_weights = posit_quantize(torch.tensor(module.weight.data, dtype=torch.float32), nsize=6, es=0, scale=scale)\n",
        "        module.weight.data = quantized_weights\n",
        "\n",
        "        print(f\"Quantized embedding layer {name} with scale factor: {scale:.2e}\")\n",
        "\n",
        "print(\"Total layers processed:\", layer_count)\n",
        "print(\"MAC operation count:\", op_count)\n",
        "\n",
        "print(\"MAC operation count:\", op_count)\n",
        "print(\"Layer count:\", layer_count)\n",
        "\n",
        "print (\"MAC operation count \", op_count)\n",
        "print (\"Layer count \", layer_count)\n",
        "\n",
        "\n",
        "# from nlp import load_dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "test = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
        "encodings = tokenizer('\\n\\n'.join(test['text']), return_tensors='pt')\n",
        "#model = model.to(device)\n",
        "def generate_text(model_new):\n",
        "  text_generation = pipeline(\"text-generation\", model=model_new, tokenizer=tokenizer, device = 0)\n",
        "  #set_seed(42)\n",
        "  prefix_texts = [\"Machine learning is the study of\",\n",
        "                    \"In the 19th century, the invention\",\n",
        "                    \"A robot was created\",\n",
        "                    \"One day I will\"\n",
        "                  ]\n",
        "  for prefix_text in prefix_texts:\n",
        "    #generated_text= text_generation(prefix_text, max_length=50, do_sample=False )[0]\n",
        "    set_seed(42)\n",
        "    generated_text= text_generation(prefix_text, max_length=50, num_return_sequences=3)\n",
        "    print(generated_text[0]['generated_text'])\n",
        "    print (\"-----------------\")\n",
        "    print(generated_text[1]['generated_text'])\n",
        "    print (\"-----------------------------------\")\n",
        "    print(generated_text[2]['generated_text'])\n",
        "    print (\"-----------------------------------\")\n",
        "generate_text(model)\n",
        "\n",
        "print (\"\\n FP32 ref : \\n\")\n",
        "# model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
        "# generate_text(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfU75mekvoTj",
        "outputId": "039cccd4-299c-4753-cad1-79b922b89c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "[0.0065918  0.02197266 0.0402832  0.0625     0.08514404 0.12109375\n",
            " 0.2109375  0.53640747]\n",
            "[0.015625   0.0625     0.125      0.1640625  0.29296875 0.4375\n",
            " 0.625      0.84375    1.         1.25       1.5        2.11486816\n",
            " 3.08789062 4.25       6.         8.25      ]\n",
            "Processing layer: transformer.h.0.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.0.attn.c_attn: -5.28\n",
            "Quantized layer transformer.h.0.attn.c_attn with scale factor: 3.88e+01\n",
            "Processing layer: transformer.h.0.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.0.attn.c_proj: -4.77\n",
            "Quantized layer transformer.h.0.attn.c_proj with scale factor: 2.72e+01\n",
            "Processing layer: transformer.h.0.mlp.c_fc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-ff6d87150e21>:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  quantized_weights = posit_quantize(torch.tensor(module.weight.data, dtype=torch.float32), nsize=8, es=0, scale=scale)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_with_max_frequency for transformer.h.0.mlp.c_fc: -4.13\n",
            "Quantized layer transformer.h.0.mlp.c_fc with scale factor: 1.75e+01\n",
            "Processing layer: transformer.h.0.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.0.mlp.c_proj: -5.48\n",
            "Quantized layer transformer.h.0.mlp.c_proj with scale factor: 4.47e+01\n",
            "Processing layer: transformer.h.1.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.1.attn.c_attn: -5.40\n",
            "Quantized layer transformer.h.1.attn.c_attn with scale factor: 4.23e+01\n",
            "Processing layer: transformer.h.1.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.1.attn.c_proj: -5.31\n",
            "Quantized layer transformer.h.1.attn.c_proj with scale factor: 3.96e+01\n",
            "Processing layer: transformer.h.1.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.1.mlp.c_fc: -4.29\n",
            "Quantized layer transformer.h.1.mlp.c_fc with scale factor: 1.96e+01\n",
            "Processing layer: transformer.h.1.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.1.mlp.c_proj: -5.11\n",
            "Quantized layer transformer.h.1.mlp.c_proj with scale factor: 3.45e+01\n",
            "Processing layer: transformer.h.2.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.2.attn.c_attn: -4.44\n",
            "Quantized layer transformer.h.2.attn.c_attn with scale factor: 2.17e+01\n",
            "Processing layer: transformer.h.2.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.2.attn.c_proj: -5.46\n",
            "Quantized layer transformer.h.2.attn.c_proj with scale factor: 4.40e+01\n",
            "Processing layer: transformer.h.2.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.2.mlp.c_fc: -3.99\n",
            "Quantized layer transformer.h.2.mlp.c_fc with scale factor: 1.58e+01\n",
            "Processing layer: transformer.h.2.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.2.mlp.c_proj: -4.92\n",
            "Quantized layer transformer.h.2.mlp.c_proj with scale factor: 3.03e+01\n",
            "Processing layer: transformer.h.3.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.3.attn.c_attn: -4.66\n",
            "Quantized layer transformer.h.3.attn.c_attn with scale factor: 2.53e+01\n",
            "Processing layer: transformer.h.3.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.3.attn.c_proj: -4.77\n",
            "Quantized layer transformer.h.3.attn.c_proj with scale factor: 2.73e+01\n",
            "Processing layer: transformer.h.3.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.3.mlp.c_fc: -4.08\n",
            "Quantized layer transformer.h.3.mlp.c_fc with scale factor: 1.69e+01\n",
            "Processing layer: transformer.h.3.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.3.mlp.c_proj: -4.58\n",
            "Quantized layer transformer.h.3.mlp.c_proj with scale factor: 2.40e+01\n",
            "Processing layer: transformer.h.4.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.4.attn.c_attn: -4.38\n",
            "Quantized layer transformer.h.4.attn.c_attn with scale factor: 2.09e+01\n",
            "Processing layer: transformer.h.4.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.4.attn.c_proj: -4.74\n",
            "Quantized layer transformer.h.4.attn.c_proj with scale factor: 2.67e+01\n",
            "Processing layer: transformer.h.4.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.4.mlp.c_fc: -4.16\n",
            "Quantized layer transformer.h.4.mlp.c_fc with scale factor: 1.78e+01\n",
            "Processing layer: transformer.h.4.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.4.mlp.c_proj: -4.59\n",
            "Quantized layer transformer.h.4.mlp.c_proj with scale factor: 2.40e+01\n",
            "Processing layer: transformer.h.5.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.5.attn.c_attn: -4.53\n",
            "Quantized layer transformer.h.5.attn.c_attn with scale factor: 2.32e+01\n",
            "Processing layer: transformer.h.5.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.5.attn.c_proj: -4.54\n",
            "Quantized layer transformer.h.5.attn.c_proj with scale factor: 2.32e+01\n",
            "Processing layer: transformer.h.5.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.5.mlp.c_fc: -4.12\n",
            "Quantized layer transformer.h.5.mlp.c_fc with scale factor: 1.74e+01\n",
            "Processing layer: transformer.h.5.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.5.mlp.c_proj: -4.43\n",
            "Quantized layer transformer.h.5.mlp.c_proj with scale factor: 2.16e+01\n",
            "Processing layer: transformer.h.6.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.6.attn.c_attn: -4.30\n",
            "Quantized layer transformer.h.6.attn.c_attn with scale factor: 1.97e+01\n",
            "Processing layer: transformer.h.6.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.6.attn.c_proj: -4.53\n",
            "Quantized layer transformer.h.6.attn.c_proj with scale factor: 2.32e+01\n",
            "Processing layer: transformer.h.6.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.6.mlp.c_fc: -4.06\n",
            "Quantized layer transformer.h.6.mlp.c_fc with scale factor: 1.67e+01\n",
            "Processing layer: transformer.h.6.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.6.mlp.c_proj: -4.46\n",
            "Quantized layer transformer.h.6.mlp.c_proj with scale factor: 2.20e+01\n",
            "Processing layer: transformer.h.7.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.7.attn.c_attn: -5.37\n",
            "Quantized layer transformer.h.7.attn.c_attn with scale factor: 4.12e+01\n",
            "Processing layer: transformer.h.7.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.7.attn.c_proj: -4.54\n",
            "Quantized layer transformer.h.7.attn.c_proj with scale factor: 2.33e+01\n",
            "Processing layer: transformer.h.7.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.7.mlp.c_fc: -4.03\n",
            "Quantized layer transformer.h.7.mlp.c_fc with scale factor: 1.64e+01\n",
            "Processing layer: transformer.h.7.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.7.mlp.c_proj: -5.02\n",
            "Quantized layer transformer.h.7.mlp.c_proj with scale factor: 3.25e+01\n",
            "Processing layer: transformer.h.8.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.8.attn.c_attn: -4.40\n",
            "Quantized layer transformer.h.8.attn.c_attn with scale factor: 2.11e+01\n",
            "Processing layer: transformer.h.8.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.8.attn.c_proj: -5.29\n",
            "Quantized layer transformer.h.8.attn.c_proj with scale factor: 3.90e+01\n",
            "Processing layer: transformer.h.8.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.8.mlp.c_fc: -4.22\n",
            "Quantized layer transformer.h.8.mlp.c_fc with scale factor: 1.86e+01\n",
            "Processing layer: transformer.h.8.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.8.mlp.c_proj: -5.04\n",
            "Quantized layer transformer.h.8.mlp.c_proj with scale factor: 3.30e+01\n",
            "Processing layer: transformer.h.9.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.9.attn.c_attn: -4.18\n",
            "Quantized layer transformer.h.9.attn.c_attn with scale factor: 1.82e+01\n",
            "Processing layer: transformer.h.9.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.9.attn.c_proj: -5.25\n",
            "Quantized layer transformer.h.9.attn.c_proj with scale factor: 3.82e+01\n",
            "Processing layer: transformer.h.9.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.9.mlp.c_fc: -4.28\n",
            "Quantized layer transformer.h.9.mlp.c_fc with scale factor: 1.94e+01\n",
            "Processing layer: transformer.h.9.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.9.mlp.c_proj: -4.44\n",
            "Quantized layer transformer.h.9.mlp.c_proj with scale factor: 2.17e+01\n",
            "Processing layer: transformer.h.10.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.10.attn.c_attn: -4.64\n",
            "Quantized layer transformer.h.10.attn.c_attn with scale factor: 2.50e+01\n",
            "Processing layer: transformer.h.10.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.10.attn.c_proj: -4.86\n",
            "Quantized layer transformer.h.10.attn.c_proj with scale factor: 2.90e+01\n",
            "Processing layer: transformer.h.10.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.10.mlp.c_fc: -4.47\n",
            "Quantized layer transformer.h.10.mlp.c_fc with scale factor: 2.22e+01\n",
            "Processing layer: transformer.h.10.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.10.mlp.c_proj: -5.06\n",
            "Quantized layer transformer.h.10.mlp.c_proj with scale factor: 3.33e+01\n",
            "Processing layer: transformer.h.11.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.11.attn.c_attn: -4.55\n",
            "Quantized layer transformer.h.11.attn.c_attn with scale factor: 2.35e+01\n",
            "Processing layer: transformer.h.11.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.11.attn.c_proj: -4.49\n",
            "Quantized layer transformer.h.11.attn.c_proj with scale factor: 2.25e+01\n",
            "Processing layer: transformer.h.11.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.11.mlp.c_fc: -4.22\n",
            "Quantized layer transformer.h.11.mlp.c_fc with scale factor: 1.86e+01\n",
            "Processing layer: transformer.h.11.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.11.mlp.c_proj: -4.83\n",
            "Quantized layer transformer.h.11.mlp.c_proj with scale factor: 2.84e+01\n",
            "Processing layer: transformer.h.12.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.12.attn.c_attn: -4.21\n",
            "Quantized layer transformer.h.12.attn.c_attn with scale factor: 1.85e+01\n",
            "Processing layer: transformer.h.12.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.12.attn.c_proj: -4.45\n",
            "Quantized layer transformer.h.12.attn.c_proj with scale factor: 2.19e+01\n",
            "Processing layer: transformer.h.12.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.12.mlp.c_fc: -4.34\n",
            "Quantized layer transformer.h.12.mlp.c_fc with scale factor: 2.03e+01\n",
            "Processing layer: transformer.h.12.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.12.mlp.c_proj: -4.59\n",
            "Quantized layer transformer.h.12.mlp.c_proj with scale factor: 2.41e+01\n",
            "Processing layer: transformer.h.13.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.13.attn.c_attn: -4.20\n",
            "Quantized layer transformer.h.13.attn.c_attn with scale factor: 1.83e+01\n",
            "Processing layer: transformer.h.13.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.13.attn.c_proj: -4.30\n",
            "Quantized layer transformer.h.13.attn.c_proj with scale factor: 1.97e+01\n",
            "Processing layer: transformer.h.13.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.13.mlp.c_fc: -4.21\n",
            "Quantized layer transformer.h.13.mlp.c_fc with scale factor: 1.85e+01\n",
            "Processing layer: transformer.h.13.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.13.mlp.c_proj: -4.99\n",
            "Quantized layer transformer.h.13.mlp.c_proj with scale factor: 3.18e+01\n",
            "Processing layer: transformer.h.14.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.14.attn.c_attn: -4.21\n",
            "Quantized layer transformer.h.14.attn.c_attn with scale factor: 1.85e+01\n",
            "Processing layer: transformer.h.14.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.14.attn.c_proj: -4.24\n",
            "Quantized layer transformer.h.14.attn.c_proj with scale factor: 1.88e+01\n",
            "Processing layer: transformer.h.14.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.14.mlp.c_fc: -4.03\n",
            "Quantized layer transformer.h.14.mlp.c_fc with scale factor: 1.63e+01\n",
            "Processing layer: transformer.h.14.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.14.mlp.c_proj: -4.46\n",
            "Quantized layer transformer.h.14.mlp.c_proj with scale factor: 2.19e+01\n",
            "Processing layer: transformer.h.15.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.15.attn.c_attn: -4.59\n",
            "Quantized layer transformer.h.15.attn.c_attn with scale factor: 2.40e+01\n",
            "Processing layer: transformer.h.15.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.15.attn.c_proj: -4.28\n",
            "Quantized layer transformer.h.15.attn.c_proj with scale factor: 1.95e+01\n",
            "Processing layer: transformer.h.15.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.15.mlp.c_fc: -4.87\n",
            "Quantized layer transformer.h.15.mlp.c_fc with scale factor: 2.92e+01\n",
            "Processing layer: transformer.h.15.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.15.mlp.c_proj: -4.45\n",
            "Quantized layer transformer.h.15.mlp.c_proj with scale factor: 2.19e+01\n",
            "Processing layer: transformer.h.16.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.16.attn.c_attn: -4.23\n",
            "Quantized layer transformer.h.16.attn.c_attn with scale factor: 1.87e+01\n",
            "Processing layer: transformer.h.16.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.16.attn.c_proj: -4.23\n",
            "Quantized layer transformer.h.16.attn.c_proj with scale factor: 1.87e+01\n",
            "Processing layer: transformer.h.16.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.16.mlp.c_fc: -4.89\n",
            "Quantized layer transformer.h.16.mlp.c_fc with scale factor: 2.97e+01\n",
            "Processing layer: transformer.h.16.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.16.mlp.c_proj: -4.97\n",
            "Quantized layer transformer.h.16.mlp.c_proj with scale factor: 3.14e+01\n",
            "Processing layer: transformer.h.17.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.17.attn.c_attn: -4.06\n",
            "Quantized layer transformer.h.17.attn.c_attn with scale factor: 1.67e+01\n",
            "Processing layer: transformer.h.17.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.17.attn.c_proj: -4.13\n",
            "Quantized layer transformer.h.17.attn.c_proj with scale factor: 1.75e+01\n",
            "Processing layer: transformer.h.17.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.17.mlp.c_fc: -4.11\n",
            "Quantized layer transformer.h.17.mlp.c_fc with scale factor: 1.72e+01\n",
            "Processing layer: transformer.h.17.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.17.mlp.c_proj: -4.52\n",
            "Quantized layer transformer.h.17.mlp.c_proj with scale factor: 2.30e+01\n",
            "Processing layer: transformer.h.18.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.18.attn.c_attn: -3.96\n",
            "Quantized layer transformer.h.18.attn.c_attn with scale factor: 1.55e+01\n",
            "Processing layer: transformer.h.18.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.18.attn.c_proj: -5.04\n",
            "Quantized layer transformer.h.18.attn.c_proj with scale factor: 3.29e+01\n",
            "Processing layer: transformer.h.18.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.18.mlp.c_fc: -4.08\n",
            "Quantized layer transformer.h.18.mlp.c_fc with scale factor: 1.69e+01\n",
            "Processing layer: transformer.h.18.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.18.mlp.c_proj: -4.50\n",
            "Quantized layer transformer.h.18.mlp.c_proj with scale factor: 2.26e+01\n",
            "Processing layer: transformer.h.19.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.19.attn.c_attn: -4.27\n",
            "Quantized layer transformer.h.19.attn.c_attn with scale factor: 1.93e+01\n",
            "Processing layer: transformer.h.19.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.19.attn.c_proj: -3.88\n",
            "Quantized layer transformer.h.19.attn.c_proj with scale factor: 1.47e+01\n",
            "Processing layer: transformer.h.19.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.19.mlp.c_fc: -4.12\n",
            "Quantized layer transformer.h.19.mlp.c_fc with scale factor: 1.73e+01\n",
            "Processing layer: transformer.h.19.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.19.mlp.c_proj: -4.54\n",
            "Quantized layer transformer.h.19.mlp.c_proj with scale factor: 2.33e+01\n",
            "Processing layer: transformer.h.20.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.20.attn.c_attn: -4.09\n",
            "Quantized layer transformer.h.20.attn.c_attn with scale factor: 1.71e+01\n",
            "Processing layer: transformer.h.20.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.20.attn.c_proj: -4.25\n",
            "Quantized layer transformer.h.20.attn.c_proj with scale factor: 1.90e+01\n",
            "Processing layer: transformer.h.20.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.20.mlp.c_fc: -4.90\n",
            "Quantized layer transformer.h.20.mlp.c_fc with scale factor: 2.98e+01\n",
            "Processing layer: transformer.h.20.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.20.mlp.c_proj: -4.50\n",
            "Quantized layer transformer.h.20.mlp.c_proj with scale factor: 2.27e+01\n",
            "Processing layer: transformer.h.21.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.21.attn.c_attn: -4.59\n",
            "Quantized layer transformer.h.21.attn.c_attn with scale factor: 2.41e+01\n",
            "Processing layer: transformer.h.21.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.21.attn.c_proj: -4.19\n",
            "Quantized layer transformer.h.21.attn.c_proj with scale factor: 1.82e+01\n",
            "Processing layer: transformer.h.21.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.21.mlp.c_fc: -4.20\n",
            "Quantized layer transformer.h.21.mlp.c_fc with scale factor: 1.84e+01\n",
            "Processing layer: transformer.h.21.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.21.mlp.c_proj: -4.48\n",
            "Quantized layer transformer.h.21.mlp.c_proj with scale factor: 2.24e+01\n",
            "Processing layer: transformer.h.22.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.22.attn.c_attn: -4.23\n",
            "Quantized layer transformer.h.22.attn.c_attn with scale factor: 1.87e+01\n",
            "Processing layer: transformer.h.22.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.22.attn.c_proj: -3.88\n",
            "Quantized layer transformer.h.22.attn.c_proj with scale factor: 1.47e+01\n",
            "Processing layer: transformer.h.22.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.22.mlp.c_fc: -4.25\n",
            "Quantized layer transformer.h.22.mlp.c_fc with scale factor: 1.91e+01\n",
            "Processing layer: transformer.h.22.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.22.mlp.c_proj: -4.45\n",
            "Quantized layer transformer.h.22.mlp.c_proj with scale factor: 2.19e+01\n",
            "Processing layer: transformer.h.23.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.23.attn.c_attn: -4.61\n",
            "Quantized layer transformer.h.23.attn.c_attn with scale factor: 2.44e+01\n",
            "Processing layer: transformer.h.23.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.23.attn.c_proj: -4.01\n",
            "Quantized layer transformer.h.23.attn.c_proj with scale factor: 1.61e+01\n",
            "Processing layer: transformer.h.23.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.23.mlp.c_fc: -4.55\n",
            "Quantized layer transformer.h.23.mlp.c_fc with scale factor: 2.35e+01\n",
            "Processing layer: transformer.h.23.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.23.mlp.c_proj: -4.48\n",
            "Quantized layer transformer.h.23.mlp.c_proj with scale factor: 2.23e+01\n",
            "Processing layer: transformer.h.24.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.24.attn.c_attn: -4.62\n",
            "Quantized layer transformer.h.24.attn.c_attn with scale factor: 2.46e+01\n",
            "Processing layer: transformer.h.24.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.24.attn.c_proj: -3.96\n",
            "Quantized layer transformer.h.24.attn.c_proj with scale factor: 1.56e+01\n",
            "Processing layer: transformer.h.24.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.24.mlp.c_fc: -4.04\n",
            "Quantized layer transformer.h.24.mlp.c_fc with scale factor: 1.64e+01\n",
            "Processing layer: transformer.h.24.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.24.mlp.c_proj: -3.73\n",
            "Quantized layer transformer.h.24.mlp.c_proj with scale factor: 1.33e+01\n",
            "Processing layer: transformer.h.25.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.25.attn.c_attn: -4.48\n",
            "Quantized layer transformer.h.25.attn.c_attn with scale factor: 2.23e+01\n",
            "Processing layer: transformer.h.25.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.25.attn.c_proj: -3.84\n",
            "Quantized layer transformer.h.25.attn.c_proj with scale factor: 1.43e+01\n",
            "Processing layer: transformer.h.25.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.25.mlp.c_fc: -4.15\n",
            "Quantized layer transformer.h.25.mlp.c_fc with scale factor: 1.78e+01\n",
            "Processing layer: transformer.h.25.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.25.mlp.c_proj: -4.10\n",
            "Quantized layer transformer.h.25.mlp.c_proj with scale factor: 1.72e+01\n",
            "Processing layer: transformer.h.26.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.26.attn.c_attn: -4.15\n",
            "Quantized layer transformer.h.26.attn.c_attn with scale factor: 1.78e+01\n",
            "Processing layer: transformer.h.26.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.26.attn.c_proj: -3.82\n",
            "Quantized layer transformer.h.26.attn.c_proj with scale factor: 1.41e+01\n",
            "Processing layer: transformer.h.26.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.26.mlp.c_fc: -4.54\n",
            "Quantized layer transformer.h.26.mlp.c_fc with scale factor: 2.33e+01\n",
            "Processing layer: transformer.h.26.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.26.mlp.c_proj: -4.21\n",
            "Quantized layer transformer.h.26.mlp.c_proj with scale factor: 1.84e+01\n",
            "Processing layer: transformer.h.27.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.27.attn.c_attn: -4.53\n",
            "Quantized layer transformer.h.27.attn.c_attn with scale factor: 2.31e+01\n",
            "Processing layer: transformer.h.27.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.27.attn.c_proj: -4.27\n",
            "Quantized layer transformer.h.27.attn.c_proj with scale factor: 1.93e+01\n",
            "Processing layer: transformer.h.27.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.27.mlp.c_fc: -4.19\n",
            "Quantized layer transformer.h.27.mlp.c_fc with scale factor: 1.82e+01\n",
            "Processing layer: transformer.h.27.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.27.mlp.c_proj: -4.29\n",
            "Quantized layer transformer.h.27.mlp.c_proj with scale factor: 1.96e+01\n",
            "Processing layer: transformer.h.28.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.28.attn.c_attn: -4.49\n",
            "Quantized layer transformer.h.28.attn.c_attn with scale factor: 2.25e+01\n",
            "Processing layer: transformer.h.28.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.28.attn.c_proj: -3.82\n",
            "Quantized layer transformer.h.28.attn.c_proj with scale factor: 1.42e+01\n",
            "Processing layer: transformer.h.28.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.28.mlp.c_fc: -4.60\n",
            "Quantized layer transformer.h.28.mlp.c_fc with scale factor: 2.42e+01\n",
            "Processing layer: transformer.h.28.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.28.mlp.c_proj: -4.12\n",
            "Quantized layer transformer.h.28.mlp.c_proj with scale factor: 1.74e+01\n",
            "Processing layer: transformer.h.29.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.29.attn.c_attn: -4.64\n",
            "Quantized layer transformer.h.29.attn.c_attn with scale factor: 2.49e+01\n",
            "Processing layer: transformer.h.29.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.29.attn.c_proj: -3.77\n",
            "Quantized layer transformer.h.29.attn.c_proj with scale factor: 1.37e+01\n",
            "Processing layer: transformer.h.29.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.29.mlp.c_fc: -4.61\n",
            "Quantized layer transformer.h.29.mlp.c_fc with scale factor: 2.45e+01\n",
            "Processing layer: transformer.h.29.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.29.mlp.c_proj: -4.23\n",
            "Quantized layer transformer.h.29.mlp.c_proj with scale factor: 1.87e+01\n",
            "Processing layer: transformer.h.30.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.30.attn.c_attn: -4.16\n",
            "Quantized layer transformer.h.30.attn.c_attn with scale factor: 1.79e+01\n",
            "Processing layer: transformer.h.30.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.30.attn.c_proj: -3.67\n",
            "Quantized layer transformer.h.30.attn.c_proj with scale factor: 1.27e+01\n",
            "Processing layer: transformer.h.30.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.30.mlp.c_fc: -4.03\n",
            "Quantized layer transformer.h.30.mlp.c_fc with scale factor: 1.64e+01\n",
            "Processing layer: transformer.h.30.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.30.mlp.c_proj: -4.17\n",
            "Quantized layer transformer.h.30.mlp.c_proj with scale factor: 1.80e+01\n",
            "Processing layer: transformer.h.31.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.31.attn.c_attn: -4.11\n",
            "Quantized layer transformer.h.31.attn.c_attn with scale factor: 1.72e+01\n",
            "Processing layer: transformer.h.31.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.31.attn.c_proj: -4.17\n",
            "Quantized layer transformer.h.31.attn.c_proj with scale factor: 1.80e+01\n",
            "Processing layer: transformer.h.31.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.31.mlp.c_fc: -4.02\n",
            "Quantized layer transformer.h.31.mlp.c_fc with scale factor: 1.62e+01\n",
            "Processing layer: transformer.h.31.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.31.mlp.c_proj: -3.98\n",
            "Quantized layer transformer.h.31.mlp.c_proj with scale factor: 1.58e+01\n",
            "Processing layer: transformer.h.32.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.32.attn.c_attn: -4.14\n",
            "Quantized layer transformer.h.32.attn.c_attn with scale factor: 1.76e+01\n",
            "Processing layer: transformer.h.32.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.32.attn.c_proj: -4.03\n",
            "Quantized layer transformer.h.32.attn.c_proj with scale factor: 1.64e+01\n",
            "Processing layer: transformer.h.32.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.32.mlp.c_fc: -4.15\n",
            "Quantized layer transformer.h.32.mlp.c_fc with scale factor: 1.77e+01\n",
            "Processing layer: transformer.h.32.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.32.mlp.c_proj: -4.02\n",
            "Quantized layer transformer.h.32.mlp.c_proj with scale factor: 1.62e+01\n",
            "Processing layer: transformer.h.33.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.33.attn.c_attn: -4.12\n",
            "Quantized layer transformer.h.33.attn.c_attn with scale factor: 1.74e+01\n",
            "Processing layer: transformer.h.33.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.33.attn.c_proj: -4.04\n",
            "Quantized layer transformer.h.33.attn.c_proj with scale factor: 1.64e+01\n",
            "Processing layer: transformer.h.33.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.33.mlp.c_fc: -4.18\n",
            "Quantized layer transformer.h.33.mlp.c_fc with scale factor: 1.82e+01\n",
            "Processing layer: transformer.h.33.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.33.mlp.c_proj: -4.24\n",
            "Quantized layer transformer.h.33.mlp.c_proj with scale factor: 1.89e+01\n",
            "Processing layer: transformer.h.34.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.34.attn.c_attn: -4.02\n",
            "Quantized layer transformer.h.34.attn.c_attn with scale factor: 1.62e+01\n",
            "Processing layer: transformer.h.34.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.34.attn.c_proj: -4.61\n",
            "Quantized layer transformer.h.34.attn.c_proj with scale factor: 2.45e+01\n",
            "Processing layer: transformer.h.34.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.34.mlp.c_fc: -4.01\n",
            "Quantized layer transformer.h.34.mlp.c_fc with scale factor: 1.61e+01\n",
            "Processing layer: transformer.h.34.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.34.mlp.c_proj: -3.96\n",
            "Quantized layer transformer.h.34.mlp.c_proj with scale factor: 1.55e+01\n",
            "Processing layer: transformer.h.35.attn.c_attn\n",
            "x_with_max_frequency for transformer.h.35.attn.c_attn: -4.20\n",
            "Quantized layer transformer.h.35.attn.c_attn with scale factor: 1.84e+01\n",
            "Processing layer: transformer.h.35.attn.c_proj\n",
            "x_with_max_frequency for transformer.h.35.attn.c_proj: -4.06\n",
            "Quantized layer transformer.h.35.attn.c_proj with scale factor: 1.67e+01\n",
            "Processing layer: transformer.h.35.mlp.c_fc\n",
            "x_with_max_frequency for transformer.h.35.mlp.c_fc: -4.78\n",
            "Quantized layer transformer.h.35.mlp.c_fc with scale factor: 2.75e+01\n",
            "Processing layer: transformer.h.35.mlp.c_proj\n",
            "x_with_max_frequency for transformer.h.35.mlp.c_proj: -3.71\n",
            "Quantized layer transformer.h.35.mlp.c_proj with scale factor: 1.31e+01\n",
            "Processing layer: lm_head\n",
            "x_with_max_frequency for lm_head: -4.20\n",
            "Quantized layer lm_head with scale factor: 1.84e+01\n",
            "Total layers processed: 145\n",
            "MAC operation count: 772117760\n",
            "MAC operation count: 772117760\n",
            "Layer count: 145\n",
            "MAC operation count  772117760\n",
            "Layer count  145\n",
            "Machine learning is the study of for the the the the the the the the the the the thethethethethethewhomomomwhomwhomwhomwhomwhomwhomomwhomwhomwhomwhomwh\n",
            "-----------------\n",
            "Machine learning is the study of the the the the the the the the the the the the the the people the's voices'\n",
            "TheS audio file of- aA aA aA aA aA aA aA nA oA\n",
            "-----------------------------------\n",
            "Machine learning is the study of course\n",
            "\" or of the a a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "-----------------------------------\n",
            "In the 19th century, the invention of the steam engine created anachronomize machine. When anachronism is at play in the industrial world of commerce,, the steam engine gives you such a tool that you can see the things\n",
            "-----------------\n",
            "In the 19th century, the invention of the electric saw was largely ignored by engineers. But the the the the the the the no the no the no the the no the no the not the not the not the not the the not the no the\n",
            "-----------------------------------\n",
            "In the 19th century, the invention of the electric motor made manufacturing a viable and its the modern use of modern electronic tools now have been in common use since the early 18th century. The first ever electric sawmill sawmill was opened by John\n",
            "-----------------------------------\n",
            "A robot was created for the production that the the the the the a the the the the the the the the at the\n",
            "the at the the at the at the at the at the at the at at the at the the at the at the at\n",
            "-----------------\n",
            "A robot was created. The The\n",
            "The\n",
            "\n",
            "TheTheThe\n",
            "\n",
            "TheThe\n",
            "\n",
            "TheThe\n",
            "\n",
            "The\n",
            "\n",
            "TheThe\n",
            "\n",
            "\n",
            "TheTheThe\n",
            "\n",
            "\n",
            "The\n",
            "\n",
            "The\n",
            "\n",
            "\n",
            "The\n",
            "\n",
            "The\n",
            "\n",
            "-----------------------------------\n",
            "A robot was created specifically to help the people in a nearby village with the problem of a nuclear accident that was threatening to occur. Now you will all notice that the robot was very helpful to a very small number of things. But a robot that you\n",
            "-----------------------------------\n",
            "One day I will go to Africa and learn something about the people.\"\n",
            "I have been asked to to\n",
            "\n",
            "Tribus\n",
            "to (a) (c) (? (? (u)(e) (d?) (? (u\n",
            "-----------------\n",
            "One day I will stop you.\"\n",
            "I did.! - - -\n",
            "And I I\n",
            "And one day I will be your you you you you you you you you you you you you you you you you you you you you you you you\n",
            "-----------------------------------\n",
            "One day I will feel the need to be a girl again,\" she added.\n",
            "A few days before the ceremony,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "-----------------------------------\n",
            "\n",
            " FP32 ref : \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.empty_cache()\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "max_length = model.config.n_positions\n",
        "stride = 1024\n",
        "\n",
        "lls = []\n",
        "input_size = encodings.input_ids.size(1)\n",
        "print(\"Input size:\", input_size)\n",
        "\n",
        "for i in tqdm(range(0, input_size, stride)):\n",
        "    begin_loc = max(i + stride - max_length, 0)\n",
        "    end_loc = min(i + stride, input_size)\n",
        "    trg_len = end_loc - i\n",
        "\n",
        "    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
        "    target_ids = input_ids.clone()\n",
        "    target_ids[:, :-trg_len] = -100\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=target_ids)\n",
        "        log_likelihood = outputs[0] * trg_len\n",
        "        # print(f\"Log Likelihood for step {i}: {log_likelihood}\")\n",
        "\n",
        "    lls.append(log_likelihood)\n",
        "\n",
        "if lls:  # Ensure lls is not empty\n",
        "    ppl = torch.exp(torch.stack(lls).sum() / input_size)\n",
        "    print(\"Perplexity:\", ppl.item())\n",
        "else:\n",
        "    print(\"No log likelihoods calculated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTsr8P3cvri2",
        "outputId": "66119382-262a-4de5-edee-1e2094f29e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size: 287644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 281/281 [02:07<00:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity: 19.721830368041992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00ad030852364c5d9a91c791967b579a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c538629f4cc442bcb3b43d0a0bf58865",
              "IPY_MODEL_b7f9d65a2a424b96942d421156932b39",
              "IPY_MODEL_ebc1e222709342ab81e7e49f3d6e58f0"
            ],
            "layout": "IPY_MODEL_b5b8259396944af190739387c4f3e987"
          }
        },
        "c538629f4cc442bcb3b43d0a0bf58865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d245544116bc41939980a2dd1291859f",
            "placeholder": "​",
            "style": "IPY_MODEL_0fc0d243561544709472a6d171374909",
            "value": "config.json: 100%"
          }
        },
        "b7f9d65a2a424b96942d421156932b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde7244069be49fab5489502a5c00389",
            "max": 666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c28630d899bb4e6992860b3e93bf515e",
            "value": 666
          }
        },
        "ebc1e222709342ab81e7e49f3d6e58f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_062f41eb2a1046808f65ea6e440f0df3",
            "placeholder": "​",
            "style": "IPY_MODEL_82f17d89785944af95b20cc3af2f138a",
            "value": " 666/666 [00:00&lt;00:00, 22.9kB/s]"
          }
        },
        "b5b8259396944af190739387c4f3e987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d245544116bc41939980a2dd1291859f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fc0d243561544709472a6d171374909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cde7244069be49fab5489502a5c00389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c28630d899bb4e6992860b3e93bf515e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "062f41eb2a1046808f65ea6e440f0df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f17d89785944af95b20cc3af2f138a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af9d5f752d0c4116b8f8a5ef96991961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8d828ebbbfb4f2b840cac7cebc1e8c6",
              "IPY_MODEL_83cf1f99cdfb47e98dfd30f7b6660936",
              "IPY_MODEL_e9d602a86e8f49b189ef4c306ae2f628"
            ],
            "layout": "IPY_MODEL_373a4c4089414f5cb857d63e269dd336"
          }
        },
        "c8d828ebbbfb4f2b840cac7cebc1e8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c009bb702dbb42a8a390492e611de786",
            "placeholder": "​",
            "style": "IPY_MODEL_33ad620366684e3aafd65ca4fe9d3837",
            "value": "model.safetensors: 100%"
          }
        },
        "83cf1f99cdfb47e98dfd30f7b6660936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4574302ffe6344cda2db49aa4799c90f",
            "max": 3247159078,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_225c77726c2443cf9907c6f342dc6989",
            "value": 3247159078
          }
        },
        "e9d602a86e8f49b189ef4c306ae2f628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e87e99711e224653900bdf4f5a46e340",
            "placeholder": "​",
            "style": "IPY_MODEL_96631b351a46456abe8267156ace46e5",
            "value": " 3.25G/3.25G [00:20&lt;00:00, 250MB/s]"
          }
        },
        "373a4c4089414f5cb857d63e269dd336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c009bb702dbb42a8a390492e611de786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ad620366684e3aafd65ca4fe9d3837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4574302ffe6344cda2db49aa4799c90f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225c77726c2443cf9907c6f342dc6989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e87e99711e224653900bdf4f5a46e340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96631b351a46456abe8267156ace46e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78404c0b802e4e9c89a49859ab6406e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6dae690b8964dc4b7270bcd31d6af37",
              "IPY_MODEL_8441693459d0482dbafb27ba6e532fcc",
              "IPY_MODEL_8279318bbd8e40699e4b9b3db3e1feea"
            ],
            "layout": "IPY_MODEL_79a60ae742c24c379d54e59dc0ef7d8c"
          }
        },
        "f6dae690b8964dc4b7270bcd31d6af37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c006b510a3cb43c5a2d8e33776ffbf5f",
            "placeholder": "​",
            "style": "IPY_MODEL_ce0d05fbf1df49d6bf6fd7a729b3a014",
            "value": "generation_config.json: 100%"
          }
        },
        "8441693459d0482dbafb27ba6e532fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ae0017ab8c4ef899693f54a572cbb8",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_150b806ba66b47dfb8fb3f2e941502ea",
            "value": 124
          }
        },
        "8279318bbd8e40699e4b9b3db3e1feea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ce38918cc34c3fb6afff61502766a2",
            "placeholder": "​",
            "style": "IPY_MODEL_f41d1255fa1740478ccdd55465546315",
            "value": " 124/124 [00:00&lt;00:00, 7.49kB/s]"
          }
        },
        "79a60ae742c24c379d54e59dc0ef7d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c006b510a3cb43c5a2d8e33776ffbf5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0d05fbf1df49d6bf6fd7a729b3a014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2ae0017ab8c4ef899693f54a572cbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "150b806ba66b47dfb8fb3f2e941502ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23ce38918cc34c3fb6afff61502766a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f41d1255fa1740478ccdd55465546315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a41b135f629f441292511e486547525a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e474c5a4f3024f709a08e8287218ba8f",
              "IPY_MODEL_44e97f109e534534b04598f341bd086b",
              "IPY_MODEL_3eb48787e3b04faea1b39441977cb032"
            ],
            "layout": "IPY_MODEL_43e9937624404bebbd8101130f140bdc"
          }
        },
        "e474c5a4f3024f709a08e8287218ba8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2debd06b648343dd9c3d2e2793c9f5bf",
            "placeholder": "​",
            "style": "IPY_MODEL_560f75060fc845959bbe92a3e9e10cdc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "44e97f109e534534b04598f341bd086b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01ea0430af0b47ebbb292b97c7fa00ce",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebb54ddafa244e4da5263217e36e089c",
            "value": 26
          }
        },
        "3eb48787e3b04faea1b39441977cb032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69204362e6ef4678971d614fb0686aca",
            "placeholder": "​",
            "style": "IPY_MODEL_27e0c123bafd44579e1ec77a17888b24",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.93kB/s]"
          }
        },
        "43e9937624404bebbd8101130f140bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2debd06b648343dd9c3d2e2793c9f5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560f75060fc845959bbe92a3e9e10cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01ea0430af0b47ebbb292b97c7fa00ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebb54ddafa244e4da5263217e36e089c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69204362e6ef4678971d614fb0686aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27e0c123bafd44579e1ec77a17888b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fce111d5fb084d369dbef665f0bda3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00739f8e753d4f7cb7a11ad8ef98184d",
              "IPY_MODEL_691ee1705e06443e96711cbef3140736",
              "IPY_MODEL_d69b05587cf64f60a8e7f8b42c3ee47b"
            ],
            "layout": "IPY_MODEL_8fbcb321cd3247ccb77b9fa3807982dd"
          }
        },
        "00739f8e753d4f7cb7a11ad8ef98184d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbaf4bd3655f49e5afa3e85c23429054",
            "placeholder": "​",
            "style": "IPY_MODEL_8579e8bcea83406287627c31c49ee4b3",
            "value": "vocab.json: 100%"
          }
        },
        "691ee1705e06443e96711cbef3140736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90f92d26cc6f44da8bfa93ba123b13e1",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_382f254a57ce4da5a0ecd9b291395669",
            "value": 1042301
          }
        },
        "d69b05587cf64f60a8e7f8b42c3ee47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ea1aaefd7244388b0af89fcf3defa7",
            "placeholder": "​",
            "style": "IPY_MODEL_c0ee4f7c6ad944fea9b42c3ab8fb175a",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.49MB/s]"
          }
        },
        "8fbcb321cd3247ccb77b9fa3807982dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbaf4bd3655f49e5afa3e85c23429054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8579e8bcea83406287627c31c49ee4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f92d26cc6f44da8bfa93ba123b13e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382f254a57ce4da5a0ecd9b291395669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26ea1aaefd7244388b0af89fcf3defa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ee4f7c6ad944fea9b42c3ab8fb175a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e2e53cdddc142fd915c9309e98f570b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c02b7a8f028544f9ba49d1836a31ce2f",
              "IPY_MODEL_840cf52790c14b98ad50643f0be8e297",
              "IPY_MODEL_5f3bda09bbf3411292b41f380522bd2a"
            ],
            "layout": "IPY_MODEL_c4ce3eb5761f4fd9a9b6293800994570"
          }
        },
        "c02b7a8f028544f9ba49d1836a31ce2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3534fdd71364144a9f4d270c18b028d",
            "placeholder": "​",
            "style": "IPY_MODEL_8dff12e8a5844b538c907310f6d1a595",
            "value": "merges.txt: 100%"
          }
        },
        "840cf52790c14b98ad50643f0be8e297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53a1b3b4b18495c99a11e5f39d396eb",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed9f7a93361c45d1bc18890c4b355766",
            "value": 456318
          }
        },
        "5f3bda09bbf3411292b41f380522bd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_912ffd0281cb44dfb011ce1d9117dff9",
            "placeholder": "​",
            "style": "IPY_MODEL_b13827923c7a4a01b81254c069ea3c2d",
            "value": " 456k/456k [00:00&lt;00:00, 5.63MB/s]"
          }
        },
        "c4ce3eb5761f4fd9a9b6293800994570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3534fdd71364144a9f4d270c18b028d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dff12e8a5844b538c907310f6d1a595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c53a1b3b4b18495c99a11e5f39d396eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9f7a93361c45d1bc18890c4b355766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "912ffd0281cb44dfb011ce1d9117dff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b13827923c7a4a01b81254c069ea3c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51adb325cf614081ac5e83b62313bc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eac5cd46cda34846869a1ab8ba750139",
              "IPY_MODEL_ffde35caf0c441c5bc2cf3253753b970",
              "IPY_MODEL_3aa7601c692144b6afe29aac12ea4a93"
            ],
            "layout": "IPY_MODEL_987ffebd2fbb4491925236934a425ecb"
          }
        },
        "eac5cd46cda34846869a1ab8ba750139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e52fae3f086b45a1b4ee9f8de1da72ae",
            "placeholder": "​",
            "style": "IPY_MODEL_7522cb91f9294e048895b0271a8950b0",
            "value": "tokenizer.json: 100%"
          }
        },
        "ffde35caf0c441c5bc2cf3253753b970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fddcc80d6224dbb9c8d12818652f293",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8110dd23c8024748a1200a6f002a4feb",
            "value": 1355256
          }
        },
        "3aa7601c692144b6afe29aac12ea4a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a777e8f71424286bafbaee44d6298dd",
            "placeholder": "​",
            "style": "IPY_MODEL_887f8c6577624e468aeedd5e0719ed47",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 13.3MB/s]"
          }
        },
        "987ffebd2fbb4491925236934a425ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e52fae3f086b45a1b4ee9f8de1da72ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7522cb91f9294e048895b0271a8950b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fddcc80d6224dbb9c8d12818652f293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8110dd23c8024748a1200a6f002a4feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a777e8f71424286bafbaee44d6298dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887f8c6577624e468aeedd5e0719ed47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}