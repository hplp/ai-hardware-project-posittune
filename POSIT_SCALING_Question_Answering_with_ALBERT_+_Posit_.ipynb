{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qfQAtRsMVl7"
      },
      "source": [
        "# Reading Comprehension with ALBERT (and similar)\n",
        "# Using Posit 6 bits for dense layers & 8 bits for the rest\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Reading comprehension, otherwise known as question answering systems, are one of the tasks that NLP tries to solve. The goal of this task is to be able to answer an arbitary question given a context. For instance, given the following context:\n",
        "\n",
        "> New Zealand (MƒÅori: Aotearoa) is a sovereign island country in the southwestern Pacific Ocean. It has a total land area of 268,000 square kilometres (103,500 sq mi), and a population of 4.9 million. New Zealand's capital city is Wellington, and its most populous city is Auckland.\n",
        "\n",
        "We ask the question\n",
        "\n",
        "> How many people live in New Zealand?\n",
        "\n",
        "We expect the QA system is to respond with something like this:\n",
        "\n",
        "> 4.9 million\n",
        "\n",
        "Since 2017, transformer models have shown to outperform existing approaches for this task. Many pretrained transformer models exist, including BERT, GPT-2, XLNET. One of the newcomers to the group is ALBERT (A Lite BERT) which was published in September 2019. The research group claims that it outperforms BERT, with much less parameters (shorter training and inference time).\n",
        "\n",
        "This tutorial demonstrates how you can fine-tune ALBERT for the task of QnA and use it for inference. For this tutorial, we will use the transformer library built by [Hugging Face](https://huggingface.co/), which is an extremely nice implementation of the transformer models (including ALBERT) in both TensorFlow and PyTorch. You can  just use a fine-tuned model from their [model repository](https://huggingface.co/models) (which I encourage in general to save money and reduce emissions). However for educational purposes I will also show you how to finetune it yourself so you can adapt it for your own data.\n",
        "\n",
        "Note that the goal of this is not to build an optimised, production ready system, but to demonstrate the concept with as little code as possible. Therefore a lot of code will be retrofitted for this purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBBHbGvQN5vX"
      },
      "source": [
        "## 1.0 Setup\n",
        "\n",
        "Let's check out what kind of GPU our friends at Google gave us. This notebook should be configured to give you a P100 üòÉ (saved in metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frTeTcy4WdbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67293303-e00f-42be-f14c-18a611034f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec  2 23:05:20 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5RImM3oWbrZ"
      },
      "source": [
        "First, we clone the Hugging Face transformer library from Github.\n",
        "\n",
        "\n",
        "Note it's checking out a specific commit only because I've tested this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOAoUwBFMQCg",
        "outputId": "6bc2a160-2fda-49db-c6f0-204488be3261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'transformers': No such file or directory\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 243432, done.\u001b[K\n",
            "remote: Counting objects: 100% (705/705), done.\u001b[K\n",
            "remote: Compressing objects: 100% (387/387), done.\u001b[K\n",
            "remote: Total 243432 (delta 415), reused 455 (delta 257), pack-reused 242727 (from 1)\u001b[K\n",
            "Receiving objects: 100% (243432/243432), 255.45 MiB | 14.56 MiB/s, done.\n",
            "Resolving deltas: 100% (178256/178256), done.\n",
            "Note: switching to 'a3085020ed0d81d4903c50967687192e3101e770'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at a3085020e Added repetition penalty to PPLM example (#2436)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.2\n",
            "Collecting qtorch-posit==0.1.1\n",
            "  Downloading qtorch_posit-0.1.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from qtorch-posit==0.1.1) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch-posit==0.1.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch-posit==0.1.1) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch-posit==0.1.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch-posit==0.1.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch-posit==0.1.1) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch-posit==0.1.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.5.0->qtorch-posit==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->qtorch-posit==0.1.1) (3.0.2)\n",
            "Downloading qtorch_posit-0.1.1-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: qtorch-posit\n",
            "Successfully installed qtorch-posit-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!rm -r transformers\n",
        "!git clone https://github.com/huggingface/transformers \\\n",
        "&& cd transformers \\\n",
        "&& git checkout a3085020ed0d81d4903c50967687192e3101e770\n",
        "!pip install ninja\n",
        "!pip install qtorch-posit==0.1.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRZned-8WJrj",
        "outputId": "28e7d92d-2a38-4a32-e3eb-d05d6bec5eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./transformers\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from transformers==2.3.0) (1.26.4)\n",
            "Collecting tokenizers==0.0.11 (from transformers==2.3.0)\n",
            "  Downloading tokenizers-0.0.11.tar.gz (30 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3 (from transformers==2.3.0)\n",
            "  Downloading boto3-1.35.72-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==2.3.0) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==2.3.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from transformers==2.3.0) (4.66.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==2.3.0) (2024.9.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformers==2.3.0) (0.2.0)\n",
            "Collecting sacremoses (from transformers==2.3.0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.72 (from boto3->transformers==2.3.0)\n",
            "  Downloading botocore-1.35.72-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->transformers==2.3.0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->transformers==2.3.0)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==2.3.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==2.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==2.3.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==2.3.0) (2024.8.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==2.3.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==2.3.0) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.72->boto3->transformers==2.3.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.72->boto3->transformers==2.3.0) (1.16.0)\n",
            "Downloading boto3-1.35.72-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.72-py3-none-any.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers, tokenizers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-py3-none-any.whl size=458542 sha256=f6cf18cedefc33bc00b275ad61a6ef921c91900ca6bdf4f1547ca3be85c61dec\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xxlx9v2u/wheels/7c/35/80/e946b22a081210c6642e607ed65b2a5b9a4d9259695ee2caf5\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully built transformers\n",
            "Failed to build tokenizers\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (4.25.5)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n",
            "Collecting botocore==1.17\n",
            "  Downloading botocore-1.17.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.17) (2.8.2)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from botocore==1.17)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting docutils<0.16,>=0.10 (from botocore==1.17)\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting urllib3<1.26,>=1.20 (from botocore==1.17)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.17) (1.16.0)\n",
            "Downloading botocore-1.17.0-py2.py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m547.6/547.6 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, jmespath, docutils, botocore\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.21.2\n",
            "    Uninstalling docutils-0.21.2:\n",
            "      Successfully uninstalled docutils-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentry-sdk 2.18.0 requires urllib3>=1.26.11, but you have urllib3 1.25.11 which is incompatible.\n",
            "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed botocore-1.17.0 docutils-0.15.2 jmespath-0.10.0 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "# original code\n",
        "!pip install ./transformers\n",
        "!pip install tensorboardX\n",
        "!pip install botocore==1.17\n",
        "\n",
        "\n",
        "# !pip install --upgrade pip setuptools wheel\n",
        "# !curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n",
        "# import os\n",
        "# os.environ['PATH'] += \":/root/.cargo/bin\"\n",
        "# !pip uninstall -y sentence-transformers\n",
        "# !pip install ./transformers\n",
        "# !pip install tensorboardX boto3 botocore==1.17\n",
        "# !pip install transformers tokenizers\n",
        "# !pip check\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHCuzhPptH0M"
      },
      "source": [
        "## 2.0 Train Model\n",
        "\n",
        "This is where we can train our own model. Note you can skip this step if you don't want to wait 1.5 hours!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaQGsAiWXcnd"
      },
      "source": [
        "### 2.1 Get Training and Evaluation Data\n",
        "\n",
        "The SQuAD dataset contains question/answer pairs to for training the ALBERT model for the QA task.\n",
        "\n",
        "Now get the SQuAD V2.0 dataset. `train-v2.0.json` is for training and `dev-v2.0.json` is for evaluation to see how well your model trained.\n",
        "\n",
        "Read more about this dataset here: https://rajpurkar.github.io/SQuAD-explorer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI6e-PfOXSnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89334cc-771d-4ba1-93ec-f7484b4beeaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-02 23:06:39--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‚Äòtrain-v2.0.json‚Äô\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M   196MB/s    in 0.2s    \n",
            "\n",
            "2024-12-02 23:06:39 (196 MB/s) - ‚Äòtrain-v2.0.json‚Äô saved [42123633/42123633]\n",
            "\n",
            "--2024-12-02 23:06:39--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‚Äòdev-v2.0.json‚Äô\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-12-02 23:06:40 (84.3 MB/s) - ‚Äòdev-v2.0.json‚Äô saved [4370528/4370528]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir dataset \\\n",
        "&& cd dataset \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JCNRkQwUD56"
      },
      "source": [
        "## 3.0 Setup prediction code and use Posit\n",
        "\n",
        "Now we can use the Hugging Face library to make predictions using our newly trained model. Note that a lot of the code is pulled from `run_squad.py` in the Hugging Face repository, with all the training parts removed. This modified code allows to run predictions we pass in directly as strings, rather .json format like the training/test set.\n",
        "\n",
        "NOTE if you decided train your own mode, change the flag `use_own_model` to `True`\n",
        "\n",
        "**Important**: this step shows how to use posit for inference by register forward_hook and forward_pre_hook for activation\n",
        "and quantization for weight. Please look at the loop:\n",
        "\n",
        "***For name, module in model.named_modules():***\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Only scale weights\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from qtorch_posit.quant import posit_quantize\n",
        "from transformers import (\n",
        "    AlbertConfig,\n",
        "    AlbertForQuestionAnswering,\n",
        "    AlbertTokenizer,\n",
        "    squad_convert_examples_to_features,\n",
        ")\n",
        "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
        "from transformers.data.metrics.squad_metrics import compute_predictions_logits, squad_evaluate\n",
        "\n",
        "# Configuration\n",
        "use_own_model = False\n",
        "model_name_or_path = \"/content/model_output\" if use_own_model else \"ktrapeznikov/albert-xlarge-v2-squad-v2\"\n",
        "epsilon = 1e-12  # To avoid log(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the model, tokenizer, and processor\n",
        "config = AlbertConfig.from_pretrained(model_name_or_path)\n",
        "tokenizer = AlbertTokenizer.from_pretrained(model_name_or_path, do_lower_case=True)\n",
        "model = AlbertForQuestionAnswering.from_pretrained(model_name_or_path, config=config)\n",
        "processor = SquadV2Processor()\n",
        "model.to(device)\n",
        "\n",
        "# Define posit quantization functions\n",
        "def linear_weight_opt(input_tensor):\n",
        "    log2_input = np.log2(np.abs(input_tensor.cpu().numpy()) + epsilon)\n",
        "    counts, bins = np.histogram(log2_input, bins=100)\n",
        "    x_with_max_frequency = (bins[np.argmax(counts)] + bins[np.argmax(counts) + 1]) / 2\n",
        "    scale = 2 ** (-x_with_max_frequency)\n",
        "    return posit_quantize(input_tensor, nsize=6, es=1, scale=scale)\n",
        "\n",
        "def other_weight_opt(input_tensor):\n",
        "    log2_input = np.log2(np.abs(input_tensor.cpu().numpy()) + epsilon)\n",
        "    counts, bins = np.histogram(log2_input, bins=100)\n",
        "    x_with_max_frequency = (bins[np.argmax(counts)] + bins[np.argmax(counts) + 1]) / 2\n",
        "    scale = 2 ** (-x_with_max_frequency)\n",
        "    return posit_quantize(input_tensor, nsize=8, es=1, scale=scale)\n",
        "\n",
        "def linear_activation_opt(input_tensor):\n",
        "    return posit_quantize(input_tensor, nsize=6, es=1)\n",
        "\n",
        "def other_activation_opt(input_tensor):\n",
        "    return posit_quantize(input_tensor, nsize=8, es=1)\n",
        "\n",
        "# Define hooks for processing layers\n",
        "def forward_pre_hook_linear_opt(m, input):\n",
        "    return (linear_activation_opt(input[0]),)\n",
        "\n",
        "def forward_hook_opt(m, input, output):\n",
        "    return other_activation_opt(output)\n",
        "\n",
        "def forward_pre_hook_other_opt(m, input):\n",
        "    if isinstance(input[0], torch.Tensor) and input[0].dtype == torch.float32:\n",
        "        return (other_activation_opt(input[0]),)\n",
        "    return input\n",
        "\n",
        "# Quantize model weights and add hooks\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, (torch.nn.Linear, torch.nn.Conv2d)):\n",
        "        print(f\"Processing linear/conv layer: {name}\")\n",
        "        module.weight.data = linear_weight_opt(module.weight.data)\n",
        "        module.register_forward_pre_hook(forward_pre_hook_linear_opt)\n",
        "        module.register_forward_hook(forward_hook_opt)\n",
        "    elif hasattr(module, 'weight') and module.weight is not None:\n",
        "        print(f\"Processing other layer: {name}\")\n",
        "        module.weight.data = other_weight_opt(module.weight.data)\n",
        "        module.register_forward_pre_hook(forward_pre_hook_other_opt)\n",
        "\n",
        "print(\"Quantization complete. Model ready for evaluation.\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate():\n",
        "    examples = processor.get_dev_examples(\"/content/dataset\", \"dev-v2.0.json\")[:1000]\n",
        "    features, dataset = squad_convert_examples_to_features(\n",
        "        examples=examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=384,\n",
        "        doc_stride=128,\n",
        "        max_query_length=64,\n",
        "        is_training=False,\n",
        "        return_dataset=\"pt\",\n",
        "        threads=1,\n",
        "    )\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=32)\n",
        "\n",
        "    all_results = []\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        with torch.no_grad():\n",
        "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"token_type_ids\": batch[2]}\n",
        "            outputs = model(**inputs)\n",
        "            example_indices = batch[3]\n",
        "            for i, example_index in enumerate(example_indices):\n",
        "                eval_feature = features[example_index.item()]\n",
        "                result = SquadResult(\n",
        "                    unique_id=int(eval_feature.unique_id),\n",
        "                    start_logits=outputs[0][i].cpu().tolist(),\n",
        "                    end_logits=outputs[1][i].cpu().tolist(),\n",
        "                )\n",
        "                all_results.append(result)\n",
        "\n",
        "    predictions = compute_predictions_logits(\n",
        "        examples,\n",
        "        features,\n",
        "        all_results,\n",
        "        n_best_size=1,\n",
        "        max_answer_length=30,\n",
        "        do_lower_case=True,\n",
        "        output_prediction_file=\"predictions.json\",\n",
        "        output_nbest_file=\"nbest_predictions.json\",\n",
        "        output_null_log_odds_file=\"null_predictions.json\",\n",
        "        verbose_logging=False,\n",
        "        version_2_with_negative=True,\n",
        "        null_score_diff_threshold=0.0,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    results = squad_evaluate(examples, predictions)\n",
        "    print(f\"Evaluation results: {results}\")\n",
        "    return results\n",
        "\n",
        "# Run evaluation\n",
        "results = evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1010,
          "referenced_widgets": [
            "c7c2905a0ebf4baab4358a56d3ce72a8",
            "4f8ec1db0ec448169c97b9e8d259eb3d",
            "90540db206ea4889bb8222ba2964ea52",
            "29263bc96c0144c3bf39c682529f58d8",
            "96202da975224c07a8ce27f53af57df7",
            "d9583f5389ff4d72abbcbf02aeb26db0",
            "f06a0cf8714e4e1ba76400bb83ca48de",
            "010eccff7e42471692a4178706e6ec9c",
            "1619b7b4dcd343d880817694e72b11f0",
            "17c2c35c35e548c4a662da921b3bc7b9",
            "28ea174e046048a38133f1e0d6410254",
            "e81cbef80da747739174af3b26ac1dca",
            "1134b0ce34534bada25a60479649325b",
            "e0584fa8fe7b4ceabbac61c193eaa930",
            "89f936f18f3649bb8844c6820e8fd865",
            "d4b53871709b4e87bae2537465c1b4e0",
            "c8f551e88c9940f18f58a42e4daff8e5",
            "3e1deb76fbb7449b8adde1108bad28cf",
            "f5eb4768d03c4df3bd1357e15e9dae15",
            "ef4c53fdf3b0479da73e2db22510f950",
            "ef0fcb0f8b2a486e94b776c824ab0e9b",
            "12ea341d6421452c984e2b8abe0de99f",
            "2a606b8b5ac94215bcd92247d36456fe",
            "70f15f175ff14292a91b1270a8ee8282",
            "07fc8ef1a6d64954b00c369f9cd09799",
            "a43f5de851e84f2a8a22fd42387a6511",
            "eefb6b329f344c9596e597c7aaed5d3f",
            "7c657671bc1b4951a1fe81547f7edb85",
            "eb2510c0a13343f3981b117f92b54ca3",
            "dcfd77a9cd884a9cb243d86614585403",
            "7f422c250e4443baba0e14405953eb77",
            "be4c344747ab4dcdaa96bafb8a272f6b",
            "d365d8f486ad4f1c82129dbdaf9241f8",
            "2200e882557f4b2bb24e21b913d29abc",
            "1741bf6935714fadb4f1ff0451a89591",
            "87c3db199ef14829bf5ec6820bbfa3a7",
            "03d624c326864a4b9cd1e6f284bd0b39",
            "2bff7318f08f45239032570b33de9975",
            "d89e1c275b794f5db04f44194754dbde",
            "7a2868aae032484aa977fcc75daeacfb",
            "1c921414d2634cdebeb7aef96cade37f",
            "965e3fc00fff407eb76bab78d95a0ba3",
            "3eefc0f95cfc49e68bc93ca2b632b3c3",
            "11b1931b11014dd1894f4db5a4a48380",
            "f276c0764ee74934bd63ae38d7a25e92",
            "3686624361724149a6113f1cd825d1bd",
            "dcafb286c1364fe69f50d0e693409a7b",
            "59ee54bc2c0a44f084a26ee04642deab",
            "bc3a0e996bb943e391cf2201359fbf8a",
            "4713fd5911984e98a88e5e723de23929",
            "23c308dc06e44c448b9bd4f5db2ae178",
            "f317ae096ba94c498c2d120888027c1f",
            "02ad15f5ed56457eb765aa849533ef75",
            "5c42bf667c1d4cc1ba1b3195e9142437",
            "b8349223382b42b790f60c49a945ac3a",
            "1a787b0a853047a69323dfd09bf358b4",
            "4d3d7ae60039465d80984b47bd2e7ddc",
            "690efaeeef3a442191ede63a9d3d2683",
            "345a9e32f49144889f5b6a7c24cbbc57",
            "98820f79219544e3ae4b8b7fd0ee89c5",
            "e9b6cdfc57284c239d689041aef03f94",
            "0617db753e12461e837c3d8e1b997790",
            "bc732d424a3a4466a4ecf731e1806db5",
            "2fd5295c0169467096b927c78f06f467",
            "7a8f4b7f34094370b3fc6478baebbc50",
            "457385e834ed4e6193459f3cae1e29b9"
          ]
        },
        "id": "O-chmWyBETqn",
        "outputId": "0a087ad6-07bd-4c59-cbf2-e42555e97cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/quant_cpu...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/quant_cpu/build.ninja...\n",
            "Building extension module quant_cpu...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module quant_cpu...\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/quant_cuda...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/quant_cuda/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module quant_cuda...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module quant_cuda...\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/717 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7c2905a0ebf4baab4358a56d3ce72a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/58.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e81cbef80da747739174af3b26ac1dca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a606b8b5ac94215bcd92247d36456fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2200e882557f4b2bb24e21b913d29abc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f276c0764ee74934bd63ae38d7a25e92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/235M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a787b0a853047a69323dfd09bf358b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ktrapeznikov/albert-xlarge-v2-squad-v2 were not used when initializing AlbertForQuestionAnswering: ['albert.pooler.bias', 'albert.pooler.weight']\n",
            "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing other layer: albert.embeddings.word_embeddings\n",
            "Processing other layer: albert.embeddings.position_embeddings\n",
            "Processing other layer: albert.embeddings.token_type_embeddings\n",
            "Processing other layer: albert.embeddings.LayerNorm\n",
            "Processing linear/conv layer: albert.encoder.embedding_hidden_mapping_in\n",
            "Processing other layer: albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense\n",
            "Processing other layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.ffn\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output\n",
            "Processing linear/conv layer: qa_outputs\n",
            "Quantization complete. Model ready for evaluation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:08<00:00,  4.36it/s]\n",
            "convert squad examples to features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:04<00:00, 220.69it/s]\n",
            "add example index and unique id: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 547059.35it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [04:20<00:00,  8.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: OrderedDict([('exact', 83.0), ('f1', 85.9574925043174), ('total', 1000), ('HasAns_exact', 78.3132530120482), ('HasAns_f1', 84.25199298055716), ('HasAns_total', 498), ('NoAns_exact', 87.64940239043824), ('NoAns_f1', 87.64940239043824), ('NoAns_total', 502), ('best_exact', 83.0), ('best_exact_thresh', 0.0), ('best_f1', 85.95749250431736), ('best_f1_thresh', 0.0)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale both weight and action\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from qtorch_posit.quant import posit_quantize\n",
        "from transformers import (\n",
        "    AlbertConfig,\n",
        "    AlbertForQuestionAnswering,\n",
        "    AlbertTokenizer,\n",
        "    squad_convert_examples_to_features,\n",
        ")\n",
        "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
        "from transformers.data.metrics.squad_metrics import compute_predictions_logits, squad_evaluate\n",
        "\n",
        "# Configuration\n",
        "use_own_model = False\n",
        "model_name_or_path = \"/content/model_output\" if use_own_model else \"ktrapeznikov/albert-xlarge-v2-squad-v2\"\n",
        "epsilon = 1e-12  # To avoid log(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the model, tokenizer, and processor\n",
        "config = AlbertConfig.from_pretrained(model_name_or_path)\n",
        "tokenizer = AlbertTokenizer.from_pretrained(model_name_or_path, do_lower_case=True)\n",
        "model = AlbertForQuestionAnswering.from_pretrained(model_name_or_path, config=config)\n",
        "processor = SquadV2Processor()\n",
        "model.to(device)\n",
        "\n",
        "# Define posit quantization functions\n",
        "def linear_weight_opt(input_tensor):\n",
        "    log2_input = np.log2(np.abs(input_tensor.cpu().numpy()) + epsilon)\n",
        "    counts, bins = np.histogram(log2_input, bins=100)\n",
        "    x_with_max_frequency = (bins[np.argmax(counts)] + bins[np.argmax(counts) + 1]) / 2\n",
        "    scale = 2 ** (-x_with_max_frequency)\n",
        "    return posit_quantize(input_tensor, nsize=6, es=1, scale=scale)\n",
        "\n",
        "def other_weight_opt(input_tensor):\n",
        "    log2_input = np.log2(np.abs(input_tensor.cpu().numpy()) + epsilon)\n",
        "    counts, bins = np.histogram(log2_input, bins=100)\n",
        "    x_with_max_frequency = (bins[np.argmax(counts)] + bins[np.argmax(counts) + 1]) / 2\n",
        "    scale = 2 ** (-x_with_max_frequency)\n",
        "    return posit_quantize(input_tensor, nsize=8, es=1, scale=scale)\n",
        "\n",
        "def linear_activation_opt(input_tensor):\n",
        "    log2_input = np.log2(np.abs(input_tensor.cpu().numpy()) + epsilon)\n",
        "    counts, bins = np.histogram(log2_input, bins=100)\n",
        "    x_with_max_frequency = (bins[np.argmax(counts)] + bins[np.argmax(counts) + 1]) / 2\n",
        "    scale = 2 ** (-x_with_max_frequency)\n",
        "    return posit_quantize(input_tensor, nsize=6, es=1, scale=scale)\n",
        "\n",
        "\n",
        "def other_activation_opt(input_tensor):\n",
        "    log2_input = np.log2(np.abs(input_tensor.cpu().numpy()) + epsilon)\n",
        "    counts, bins = np.histogram(log2_input, bins=100)\n",
        "    x_with_max_frequency = (bins[np.argmax(counts)] + bins[np.argmax(counts) + 1]) / 2\n",
        "    scale = 2 ** (-x_with_max_frequency)\n",
        "    return posit_quantize(input_tensor, nsize=8, es=1, scale = scale)\n",
        "\n",
        "# Define hooks for processing layers\n",
        "def forward_pre_hook_linear_opt(m, input):\n",
        "    return (linear_activation_opt(input[0]),)\n",
        "\n",
        "def forward_hook_opt(m, input, output):\n",
        "    return other_activation_opt(output)\n",
        "\n",
        "def forward_pre_hook_other_opt(m, input):\n",
        "    if isinstance(input[0], torch.Tensor) and input[0].dtype == torch.float32:\n",
        "        return (other_activation_opt(input[0]),)\n",
        "    return input\n",
        "\n",
        "# Quantize model weights and add hooks\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, (torch.nn.Linear, torch.nn.Conv2d)):\n",
        "        print(f\"Processing linear/conv layer: {name}\")\n",
        "        module.weight.data = linear_weight_opt(module.weight.data)\n",
        "        module.register_forward_pre_hook(forward_pre_hook_linear_opt)\n",
        "        module.register_forward_hook(forward_hook_opt)\n",
        "    elif hasattr(module, 'weight') and module.weight is not None:\n",
        "        print(f\"Processing other layer: {name}\")\n",
        "        module.weight.data = other_weight_opt(module.weight.data)\n",
        "        module.register_forward_pre_hook(forward_pre_hook_other_opt)\n",
        "\n",
        "print(\"Quantization complete. Model ready for evaluation.\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate():\n",
        "    examples = processor.get_dev_examples(\"/content/dataset\", \"dev-v2.0.json\")[:1000]\n",
        "    features, dataset = squad_convert_examples_to_features(\n",
        "        examples=examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=384,\n",
        "        doc_stride=128,\n",
        "        max_query_length=64,\n",
        "        is_training=False,\n",
        "        return_dataset=\"pt\",\n",
        "        threads=1,\n",
        "    )\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=32)\n",
        "\n",
        "    all_results = []\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        with torch.no_grad():\n",
        "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"token_type_ids\": batch[2]}\n",
        "            outputs = model(**inputs)\n",
        "            example_indices = batch[3]\n",
        "            for i, example_index in enumerate(example_indices):\n",
        "                eval_feature = features[example_index.item()]\n",
        "                result = SquadResult(\n",
        "                    unique_id=int(eval_feature.unique_id),\n",
        "                    start_logits=outputs[0][i].cpu().tolist(),\n",
        "                    end_logits=outputs[1][i].cpu().tolist(),\n",
        "                )\n",
        "                all_results.append(result)\n",
        "\n",
        "    predictions = compute_predictions_logits(\n",
        "        examples,\n",
        "        features,\n",
        "        all_results,\n",
        "        n_best_size=1,\n",
        "        max_answer_length=30,\n",
        "        do_lower_case=True,\n",
        "        output_prediction_file=\"predictions.json\",\n",
        "        output_nbest_file=\"nbest_predictions.json\",\n",
        "        output_null_log_odds_file=\"null_predictions.json\",\n",
        "        verbose_logging=False,\n",
        "        version_2_with_negative=True,\n",
        "        null_score_diff_threshold=0.0,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    results = squad_evaluate(examples, predictions)\n",
        "    print(f\"Evaluation results: {results}\")\n",
        "    return results\n",
        "\n",
        "# Run evaluation\n",
        "results = evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WJzgGJbIG-j",
        "outputId": "a8d2ba2e-11fa-4d41-9f81-954d8f7ad972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ktrapeznikov/albert-xlarge-v2-squad-v2 were not used when initializing AlbertForQuestionAnswering: ['albert.pooler.bias', 'albert.pooler.weight']\n",
            "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing other layer: albert.embeddings.word_embeddings\n",
            "Processing other layer: albert.embeddings.position_embeddings\n",
            "Processing other layer: albert.embeddings.token_type_embeddings\n",
            "Processing other layer: albert.embeddings.LayerNorm\n",
            "Processing linear/conv layer: albert.encoder.embedding_hidden_mapping_in\n",
            "Processing other layer: albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense\n",
            "Processing other layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.ffn\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output\n",
            "Processing linear/conv layer: qa_outputs\n",
            "Quantization complete. Model ready for evaluation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:05<00:00,  6.57it/s]\n",
            "convert squad examples to features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:05<00:00, 177.83it/s]\n",
            "add example index and unique id: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 554802.12it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [2:08:39<00:00, 241.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: OrderedDict([('exact', 82.9), ('f1', 85.85728354978349), ('total', 1000), ('HasAns_exact', 78.3132530120482), ('HasAns_f1', 84.2515733931397), ('HasAns_total', 498), ('NoAns_exact', 87.45019920318725), ('NoAns_f1', 87.45019920318725), ('NoAns_total', 502), ('best_exact', 82.9), ('best_exact_thresh', 0.0), ('best_f1', 85.85728354978346), ('best_f1_thresh', 0.0)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale linear weight and activation\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from qtorch_posit.quant import posit_quantize\n",
        "from transformers import (\n",
        "    AlbertConfig,\n",
        "    AlbertForQuestionAnswering,\n",
        "    AlbertTokenizer,\n",
        "    squad_convert_examples_to_features,\n",
        ")\n",
        "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
        "from transformers.data.metrics.squad_metrics import compute_predictions_logits, squad_evaluate\n",
        "\n",
        "# Configuration\n",
        "use_own_model = False\n",
        "model_name_or_path = \"/content/model_output\" if use_own_model else \"ktrapeznikov/albert-xlarge-v2-squad-v2\"\n",
        "epsilon = 1e-12  # To avoid log(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the model, tokenizer, and processor\n",
        "config = AlbertConfig.from_pretrained(model_name_or_path)\n",
        "tokenizer = AlbertTokenizer.from_pretrained(model_name_or_path, do_lower_case=True)\n",
        "model = AlbertForQuestionAnswering.from_pretrained(model_name_or_path, config=config)\n",
        "processor = SquadV2Processor()\n",
        "model.to(device)\n",
        "\n",
        "# Define posit quantization functions\n",
        "def linear_weight_opt(input_tensor):\n",
        "    log2_input = np.log2(np.abs(input_tensor.cpu().numpy()) + epsilon)\n",
        "    counts, bins = np.histogram(log2_input, bins=100)\n",
        "    x_with_max_frequency = (bins[np.argmax(counts)] + bins[np.argmax(counts) + 1]) / 2\n",
        "    scale = 2 ** (-x_with_max_frequency)\n",
        "    return posit_quantize(input_tensor, nsize=6, es=1, scale=scale)\n",
        "\n",
        "def other_weight_opt(input_tensor):\n",
        "\n",
        "    return posit_quantize(input_tensor, nsize=8, es=1)\n",
        "\n",
        "def linear_activation_opt(input_tensor):\n",
        "    log2_input = np.log2(np.abs(input_tensor.cpu().numpy()) + epsilon)\n",
        "    counts, bins = np.histogram(log2_input, bins=100)\n",
        "    x_with_max_frequency = (bins[np.argmax(counts)] + bins[np.argmax(counts) + 1]) / 2\n",
        "    scale = 2 ** (-x_with_max_frequency)\n",
        "    return posit_quantize(input_tensor, nsize=6, es=1, scale=scale)\n",
        "\n",
        "\n",
        "def other_activation_opt(input_tensor):\n",
        "\n",
        "    return posit_quantize(input_tensor, nsize=8, es=1)\n",
        "\n",
        "# Define hooks for processing layers\n",
        "def forward_pre_hook_linear_opt(m, input):\n",
        "    return (linear_activation_opt(input[0]),)\n",
        "\n",
        "def forward_hook_opt(m, input, output):\n",
        "    return other_activation_opt(output)\n",
        "\n",
        "def forward_pre_hook_other_opt(m, input):\n",
        "    if isinstance(input[0], torch.Tensor) and input[0].dtype == torch.float32:\n",
        "        return (other_activation_opt(input[0]),)\n",
        "    return input\n",
        "\n",
        "# Quantize model weights and add hooks\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, (torch.nn.Linear, torch.nn.Conv2d)):\n",
        "        print(f\"Processing linear/conv layer: {name}\")\n",
        "        module.weight.data = linear_weight_opt(module.weight.data)\n",
        "        module.register_forward_pre_hook(forward_pre_hook_linear_opt)\n",
        "        module.register_forward_hook(forward_hook_opt)\n",
        "    elif hasattr(module, 'weight') and module.weight is not None:\n",
        "        print(f\"Processing other layer: {name}\")\n",
        "        module.weight.data = other_weight_opt(module.weight.data)\n",
        "        module.register_forward_pre_hook(forward_pre_hook_other_opt)\n",
        "\n",
        "print(\"Quantization complete. Model ready for evaluation.\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate():\n",
        "    examples = processor.get_dev_examples(\"/content/dataset\", \"dev-v2.0.json\")[:1000]\n",
        "    features, dataset = squad_convert_examples_to_features(\n",
        "        examples=examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=384,\n",
        "        doc_stride=128,\n",
        "        max_query_length=64,\n",
        "        is_training=False,\n",
        "        return_dataset=\"pt\",\n",
        "        threads=1,\n",
        "    )\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=32)\n",
        "\n",
        "    all_results = []\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        with torch.no_grad():\n",
        "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"token_type_ids\": batch[2]}\n",
        "            outputs = model(**inputs)\n",
        "            example_indices = batch[3]\n",
        "            for i, example_index in enumerate(example_indices):\n",
        "                eval_feature = features[example_index.item()]\n",
        "                result = SquadResult(\n",
        "                    unique_id=int(eval_feature.unique_id),\n",
        "                    start_logits=outputs[0][i].cpu().tolist(),\n",
        "                    end_logits=outputs[1][i].cpu().tolist(),\n",
        "                )\n",
        "                all_results.append(result)\n",
        "\n",
        "    predictions = compute_predictions_logits(\n",
        "        examples,\n",
        "        features,\n",
        "        all_results,\n",
        "        n_best_size=1,\n",
        "        max_answer_length=30,\n",
        "        do_lower_case=True,\n",
        "        output_prediction_file=\"predictions.json\",\n",
        "        output_nbest_file=\"nbest_predictions.json\",\n",
        "        output_null_log_odds_file=\"null_predictions.json\",\n",
        "        verbose_logging=False,\n",
        "        version_2_with_negative=True,\n",
        "        null_score_diff_threshold=0.0,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    results = squad_evaluate(examples, predictions)\n",
        "    print(f\"Evaluation results: {results}\")\n",
        "    return results\n",
        "\n",
        "# Run evaluation\n",
        "results = evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38nde8S9MUxW",
        "outputId": "4de320b9-9c40-4fba-bbef-76b431ec9126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ktrapeznikov/albert-xlarge-v2-squad-v2 were not used when initializing AlbertForQuestionAnswering: ['albert.pooler.bias', 'albert.pooler.weight']\n",
            "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing other layer: albert.embeddings.word_embeddings\n",
            "Processing other layer: albert.embeddings.position_embeddings\n",
            "Processing other layer: albert.embeddings.token_type_embeddings\n",
            "Processing other layer: albert.embeddings.LayerNorm\n",
            "Processing linear/conv layer: albert.encoder.embedding_hidden_mapping_in\n",
            "Processing other layer: albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense\n",
            "Processing other layer: albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.ffn\n",
            "Processing linear/conv layer: albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output\n",
            "Processing linear/conv layer: qa_outputs\n",
            "Quantization complete. Model ready for evaluation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:04<00:00,  8.39it/s]\n",
            "convert squad examples to features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:05<00:00, 189.36it/s]\n",
            "add example index and unique id: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 571353.22it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [1:00:21<00:00, 113.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: OrderedDict([('exact', 84.1), ('f1', 86.93163244650081), ('total', 1000), ('HasAns_exact', 80.32128514056225), ('HasAns_f1', 86.0072940692789), ('HasAns_total', 498), ('NoAns_exact', 87.84860557768924), ('NoAns_f1', 87.84860557768924), ('NoAns_total', 502), ('best_exact', 84.1), ('best_exact_thresh', 0.0), ('best_f1', 86.9316324465008), ('best_f1_thresh', 0.0)])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7c2905a0ebf4baab4358a56d3ce72a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f8ec1db0ec448169c97b9e8d259eb3d",
              "IPY_MODEL_90540db206ea4889bb8222ba2964ea52",
              "IPY_MODEL_29263bc96c0144c3bf39c682529f58d8"
            ],
            "layout": "IPY_MODEL_96202da975224c07a8ce27f53af57df7"
          }
        },
        "4f8ec1db0ec448169c97b9e8d259eb3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9583f5389ff4d72abbcbf02aeb26db0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f06a0cf8714e4e1ba76400bb83ca48de",
            "value": "config.json:‚Äá100%"
          }
        },
        "90540db206ea4889bb8222ba2964ea52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010eccff7e42471692a4178706e6ec9c",
            "max": 717,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1619b7b4dcd343d880817694e72b11f0",
            "value": 717
          }
        },
        "29263bc96c0144c3bf39c682529f58d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c2c35c35e548c4a662da921b3bc7b9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_28ea174e046048a38133f1e0d6410254",
            "value": "‚Äá717/717‚Äá[00:00&lt;00:00,‚Äá37.1kB/s]"
          }
        },
        "96202da975224c07a8ce27f53af57df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9583f5389ff4d72abbcbf02aeb26db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06a0cf8714e4e1ba76400bb83ca48de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "010eccff7e42471692a4178706e6ec9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1619b7b4dcd343d880817694e72b11f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17c2c35c35e548c4a662da921b3bc7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ea174e046048a38133f1e0d6410254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e81cbef80da747739174af3b26ac1dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1134b0ce34534bada25a60479649325b",
              "IPY_MODEL_e0584fa8fe7b4ceabbac61c193eaa930",
              "IPY_MODEL_89f936f18f3649bb8844c6820e8fd865"
            ],
            "layout": "IPY_MODEL_d4b53871709b4e87bae2537465c1b4e0"
          }
        },
        "1134b0ce34534bada25a60479649325b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8f551e88c9940f18f58a42e4daff8e5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3e1deb76fbb7449b8adde1108bad28cf",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "e0584fa8fe7b4ceabbac61c193eaa930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5eb4768d03c4df3bd1357e15e9dae15",
            "max": 58,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef4c53fdf3b0479da73e2db22510f950",
            "value": 58
          }
        },
        "89f936f18f3649bb8844c6820e8fd865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef0fcb0f8b2a486e94b776c824ab0e9b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_12ea341d6421452c984e2b8abe0de99f",
            "value": "‚Äá58.0/58.0‚Äá[00:00&lt;00:00,‚Äá3.92kB/s]"
          }
        },
        "d4b53871709b4e87bae2537465c1b4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f551e88c9940f18f58a42e4daff8e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1deb76fbb7449b8adde1108bad28cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5eb4768d03c4df3bd1357e15e9dae15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef4c53fdf3b0479da73e2db22510f950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef0fcb0f8b2a486e94b776c824ab0e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ea341d6421452c984e2b8abe0de99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a606b8b5ac94215bcd92247d36456fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70f15f175ff14292a91b1270a8ee8282",
              "IPY_MODEL_07fc8ef1a6d64954b00c369f9cd09799",
              "IPY_MODEL_a43f5de851e84f2a8a22fd42387a6511"
            ],
            "layout": "IPY_MODEL_eefb6b329f344c9596e597c7aaed5d3f"
          }
        },
        "70f15f175ff14292a91b1270a8ee8282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c657671bc1b4951a1fe81547f7edb85",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eb2510c0a13343f3981b117f92b54ca3",
            "value": "spiece.model:‚Äá100%"
          }
        },
        "07fc8ef1a6d64954b00c369f9cd09799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcfd77a9cd884a9cb243d86614585403",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f422c250e4443baba0e14405953eb77",
            "value": 760289
          }
        },
        "a43f5de851e84f2a8a22fd42387a6511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4c344747ab4dcdaa96bafb8a272f6b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d365d8f486ad4f1c82129dbdaf9241f8",
            "value": "‚Äá760k/760k‚Äá[00:00&lt;00:00,‚Äá3.95MB/s]"
          }
        },
        "eefb6b329f344c9596e597c7aaed5d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c657671bc1b4951a1fe81547f7edb85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2510c0a13343f3981b117f92b54ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcfd77a9cd884a9cb243d86614585403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f422c250e4443baba0e14405953eb77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be4c344747ab4dcdaa96bafb8a272f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d365d8f486ad4f1c82129dbdaf9241f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2200e882557f4b2bb24e21b913d29abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1741bf6935714fadb4f1ff0451a89591",
              "IPY_MODEL_87c3db199ef14829bf5ec6820bbfa3a7",
              "IPY_MODEL_03d624c326864a4b9cd1e6f284bd0b39"
            ],
            "layout": "IPY_MODEL_2bff7318f08f45239032570b33de9975"
          }
        },
        "1741bf6935714fadb4f1ff0451a89591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d89e1c275b794f5db04f44194754dbde",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7a2868aae032484aa977fcc75daeacfb",
            "value": "added_tokens.json:‚Äá100%"
          }
        },
        "87c3db199ef14829bf5ec6820bbfa3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c921414d2634cdebeb7aef96cade37f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_965e3fc00fff407eb76bab78d95a0ba3",
            "value": 2
          }
        },
        "03d624c326864a4b9cd1e6f284bd0b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eefc0f95cfc49e68bc93ca2b632b3c3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_11b1931b11014dd1894f4db5a4a48380",
            "value": "‚Äá2.00/2.00‚Äá[00:00&lt;00:00,‚Äá126B/s]"
          }
        },
        "2bff7318f08f45239032570b33de9975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89e1c275b794f5db04f44194754dbde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a2868aae032484aa977fcc75daeacfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c921414d2634cdebeb7aef96cade37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965e3fc00fff407eb76bab78d95a0ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3eefc0f95cfc49e68bc93ca2b632b3c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11b1931b11014dd1894f4db5a4a48380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f276c0764ee74934bd63ae38d7a25e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3686624361724149a6113f1cd825d1bd",
              "IPY_MODEL_dcafb286c1364fe69f50d0e693409a7b",
              "IPY_MODEL_59ee54bc2c0a44f084a26ee04642deab"
            ],
            "layout": "IPY_MODEL_bc3a0e996bb943e391cf2201359fbf8a"
          }
        },
        "3686624361724149a6113f1cd825d1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4713fd5911984e98a88e5e723de23929",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_23c308dc06e44c448b9bd4f5db2ae178",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "dcafb286c1364fe69f50d0e693409a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f317ae096ba94c498c2d120888027c1f",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02ad15f5ed56457eb765aa849533ef75",
            "value": 156
          }
        },
        "59ee54bc2c0a44f084a26ee04642deab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c42bf667c1d4cc1ba1b3195e9142437",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b8349223382b42b790f60c49a945ac3a",
            "value": "‚Äá156/156‚Äá[00:00&lt;00:00,‚Äá10.1kB/s]"
          }
        },
        "bc3a0e996bb943e391cf2201359fbf8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4713fd5911984e98a88e5e723de23929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c308dc06e44c448b9bd4f5db2ae178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f317ae096ba94c498c2d120888027c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ad15f5ed56457eb765aa849533ef75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c42bf667c1d4cc1ba1b3195e9142437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8349223382b42b790f60c49a945ac3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a787b0a853047a69323dfd09bf358b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d3d7ae60039465d80984b47bd2e7ddc",
              "IPY_MODEL_690efaeeef3a442191ede63a9d3d2683",
              "IPY_MODEL_345a9e32f49144889f5b6a7c24cbbc57"
            ],
            "layout": "IPY_MODEL_98820f79219544e3ae4b8b7fd0ee89c5"
          }
        },
        "4d3d7ae60039465d80984b47bd2e7ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b6cdfc57284c239d689041aef03f94",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0617db753e12461e837c3d8e1b997790",
            "value": "pytorch_model.bin:‚Äá100%"
          }
        },
        "690efaeeef3a442191ede63a9d3d2683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc732d424a3a4466a4ecf731e1806db5",
            "max": 234922444,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fd5295c0169467096b927c78f06f467",
            "value": 234922444
          }
        },
        "345a9e32f49144889f5b6a7c24cbbc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8f4b7f34094370b3fc6478baebbc50",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_457385e834ed4e6193459f3cae1e29b9",
            "value": "‚Äá235M/235M‚Äá[00:01&lt;00:00,‚Äá240MB/s]"
          }
        },
        "98820f79219544e3ae4b8b7fd0ee89c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b6cdfc57284c239d689041aef03f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0617db753e12461e837c3d8e1b997790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc732d424a3a4466a4ecf731e1806db5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fd5295c0169467096b927c78f06f467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a8f4b7f34094370b3fc6478baebbc50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457385e834ed4e6193459f3cae1e29b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}